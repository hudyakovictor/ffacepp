#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ü–û–õ–ù–û–°–¢–¨–Æ –ü–ï–†–ï–ü–ò–°–ê–ù–ù–ê–Ø –°–ò–°–¢–ï–ú–ê –ê–ù–ê–õ–ò–ó–ê –õ–ò–¶ –° 3DDFA_V2
–°–æ—Ö—Ä–∞–Ω–µ–Ω—ã –í–°–ï —Ñ—É–Ω–∫—Ü–∏–∏ + –∏—Å–ø—Ä–∞–≤–ª–µ–Ω—ã –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –º–µ—Ç—Ä–∏–∫
–í–µ—Ä—Å–∏—è: 6.0 - –°—Ç–∞–±–∏–ª—å–Ω–∞—è
"""

import sys
import argparse
import cv2
import yaml
import json
import os
import numpy as np
import math
import traceback
from scipy.spatial.distance import cosine
from typing import Dict, List, Tuple, Optional, Union
import warnings
import logging
from pathlib import Path
import time

warnings.filterwarnings('ignore')

# –î–æ–±–∞–≤–ª—è–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é —Ç–µ–∫—É—â–µ–≥–æ —Å–∫—Ä–∏–ø—Ç–∞ –≤ sys.path
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
if SCRIPT_DIR not in sys.path:
    sys.path.append(SCRIPT_DIR)

# –ò–º–ø–æ—Ä—Ç—ã 3DDFA_V2
from FaceBoxes import FaceBoxes
from TDDFA import TDDFA
from utils.render import render
from utils.depth import depth
from utils.pncc import pncc
from utils.uv import uv_tex
from utils.pose import viz_pose, P2sRt, matrix2angle
from utils.serialization import ser_to_ply, ser_to_obj
from utils.functions import draw_landmarks, get_suffix
from utils.tddfa_util import str2bool, _parse_param

# –ò–º–ø–æ—Ä—Ç—ã InsightFace
import insightface
from insightface.app import FaceAnalysis

# –ò–º–ø–æ—Ä—Ç—ã –º–æ–¥—É–ª–µ–π –∞–Ω–∞–ª–∏–∑–∞
from frontal_metrics import FrontalAnalysisModule
from frontal_edge_metrics import FrontalEdgeAnalysisModule
from semi_profile_metrics import SemiProfileAnalysisModule
from profile_metrics import ProfileAnalysisModule

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
INSIGHT_FACE_THRESHOLD = 0.363
EPSILON = 1e-6
SUPPORTED_FORMATS = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp')

class NumpyEncoder(json.JSONEncoder):
    """JSON —ç–Ω–∫–æ–¥–µ—Ä –¥–ª—è NumPy —Ç–∏–ø–æ–≤"""
    def default(self, o):
        if isinstance(o, np.integer):
            return int(o)
        elif isinstance(o, np.floating):
            if np.isnan(o) or np.isinf(o):
                return None
            return round(float(o), 6)
        elif isinstance(o, np.ndarray):
            return o.tolist()
        elif isinstance(o, np.bool_):
            return bool(o)
        return super(NumpyEncoder, self).default(o)

class UnionFind:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–≤—è–∑–µ–π"""
    def __init__(self):
        self.parent = {}
        self.rank = {}

    def find(self, x):
        if x not in self.parent:
            self.parent[x] = x
            self.rank[x] = 0
        if self.parent[x] != x:
            self.parent[x] = self.find(self.parent[x])
        return self.parent[x]

    def union(self, x, y):
        px, py = self.find(x), self.find(y)
        if px != py:
            if self.rank[px] < self.rank[py]:
                px, py = py, px
            self.parent[py] = px
            if self.rank[px] == self.rank[py]:
                self.rank[px] += 1

class Enhanced3DFaceProcessor:
    """–ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ 3D –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç —Å–æ–≥–ª–∞—Å–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ 3DDFA_V2"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞"""
        self.logger = logging.getLogger('Enhanced3DFaceProcessor')

    def _get_default_parameters(self):
        return {
            'R_matrix': np.eye(3, dtype=np.float32),
            't_vec': np.zeros(3, dtype=np.float32),
            's_scale': 1.0,
            'offset': np.zeros(2, dtype=np.float32),
            'alpha_shp': np.zeros(40, dtype=np.float32),
            'alpha_exp': np.zeros(10, dtype=np.float32),
            'pitch': 0.0,
            'yaw': 0.0,
            'roll': 0.0,
            'P_matrix': np.eye(3, 4, dtype=np.float32)
        }

    def extract_pose_and_shape_parameters(self, params):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∑—ã –∏ —Ñ–æ—Ä–º—ã –∏–∑ param_lst"""
        if params is None:
            return None
            
        param = _parse_param(params)
        P, scale, pose = P2sRt(param)  # P2sRt –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç 3 –∑–Ω–∞—á–µ–Ω–∏—è
        camera_params = {'P': P, 'scale': scale}
        
        # –ü–æ–ª—É—á–∞–µ–º —É–≥–ª—ã –≠–π–ª–µ—Ä–∞
        _, yaw, pitch = matrix2angle(pose)
        R_matrix = pose  # –ú–∞—Ç—Ä–∏—Ü–∞ –ø–æ–≤–æ—Ä–æ—Ç–∞
        
        return {
            'yaw': yaw,
            'pitch': pitch,
            'R_matrix': R_matrix,
            'camera_params': camera_params
        }
    
    def extract_pose_and_shape_parameters(self, param_3dmm: np.ndarray) -> Dict:
        """–ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏–µ–π –ø–æ–∑—ã"""
        try:
            # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –æ–¥–Ω–æ–º–µ—Ä–Ω–æ–º—É –º–∞—Å—Å–∏–≤—É
            param_3dmm = np.asarray(param_3dmm).flatten()
            if param_3dmm is None or len(param_3dmm) < 12:
                self.logger.warning(f"param_3dmm –ø—É—Å—Ç–æ–π –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π: {param_3dmm}")
                return self._get_default_parameters()
            if len(param_3dmm) not in (62, 72, 141):
                self.logger.error(f"param_3dmm –∏–º–µ–µ—Ç –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—É—é –¥–ª–∏–Ω—É: {len(param_3dmm)}")
                return self._get_default_parameters()

            # 1. –ò–∑–≤–ª–µ–∫–∞–µ–º –±–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∑—ã
            # _parse_param –¥–æ–ª–∂–µ–Ω –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –∫–æ—Ä—Ç–µ–∂ (R, t3d, s, ...)
            parsed = _parse_param(param_3dmm)
            if isinstance(parsed, (list, tuple)) and len(parsed) >= 3:
                R, t3d, s = parsed[:3]
            else:
                self.logger.error(f"_parse_param –≤–µ—Ä–Ω—É–ª –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {parsed}")
                return self._get_default_parameters()

            P_camera = np.eye(3, 4)
            pitch, yaw, roll = matrix2angle(R)

            # 2. –ö–æ–º–ø–µ–Ω—Å–∞—Ü–∏—è –∏—Å–∫–∞–∂–µ–Ω–∏–π –≤ –º–∞—Ç—Ä–∏—Ü–µ –ø–æ–≤–æ—Ä–æ—Ç–∞
            max_angle = 75.0  # –≥—Ä–∞–¥—É—Å—ã
            pitch_deg = float(np.degrees(pitch))
            yaw_deg = float(np.degrees(yaw))
            roll_deg = float(np.degrees(roll))
            pitch_deg = np.clip(pitch_deg, -max_angle, max_angle)
            yaw_deg = np.clip(yaw_deg, -max_angle, max_angle)
            roll_deg = np.clip(roll_deg, -30.0, 30.0)
            pitch = np.radians(pitch_deg)
            yaw = np.radians(yaw_deg)
            roll = np.radians(roll_deg)
            Rx = np.array([[1, 0, 0],
                          [0, np.cos(pitch), -np.sin(pitch)],
                          [0, np.sin(pitch), np.cos(pitch)]])
            Ry = np.array([[np.cos(yaw), 0, np.sin(yaw)],
                          [0, 1, 0],
                          [-np.sin(yaw), 0, np.cos(yaw)]])
            Rz = np.array([[np.cos(roll), -np.sin(roll), 0],
                          [np.sin(roll), np.cos(roll), 0],
                          [0, 0, 1]])
            R_compensated = Rz @ Ry @ Rx

            # 3. –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ–æ—Ä–º—ã –∏ –≤—ã—Ä–∞–∂–µ–Ω–∏—è
            if len(param_3dmm) >= 72:
                alpha_shp = param_3dmm[12:52]  # 40 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Ñ–æ—Ä–º—ã
                alpha_exp = param_3dmm[52:62]  # 10 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤—ã—Ä–∞–∂–µ–Ω–∏—è
                offset = param_3dmm[62:64] if len(param_3dmm) > 64 else np.zeros(2)
            else:
                alpha_shp = np.zeros(40, dtype=np.float32)
                alpha_exp = np.zeros(10, dtype=np.float32)
                offset = np.zeros(2, dtype=np.float32)

            # 4. –ü—Ä–∏–º–µ–Ω—è–µ–º –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏ –ø–æ–∑—ã
            # s –º–æ–∂–µ—Ç –±—ã—Ç—å –º–∞—Å—Å–∏–≤–æ–º, –ø—Ä–∏–≤–æ–¥–∏–º –∫ float
            if isinstance(s, (np.ndarray, list)):
                s_stable = float(np.squeeze(s))
            else:
                s_stable = float(s)
            if abs(yaw_deg) > 30.0 or abs(pitch_deg) > 30.0:
                perspective_factor = 1.0 + 0.002 * (abs(yaw_deg) + abs(pitch_deg))
                s_stable *= perspective_factor

            return {
                'R_matrix': R_compensated.astype(np.float32),
                't_vec': t3d.astype(np.float32),
                's_scale': float(s_stable),
                'offset': offset.astype(np.float32),
                'alpha_shp': alpha_shp.astype(np.float32),
                'alpha_exp': alpha_exp.astype(np.float32),
                'pitch': pitch_deg,
                'yaw': yaw_deg,
                'roll': roll_deg,
                'P_matrix': P_camera.astype(np.float32)
            }
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {e}")
            return self._get_default_parameters()
    
    def transform_to_frontal_view(self, landmarks_3d: np.ndarray, R_matrix: np.ndarray) -> np.ndarray:
        """–ò–°–ü–†–ê–í–õ–ï–ù–û: –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è landmarks –≤ —Ñ—Ä–æ–Ω—Ç–∞–ª—å–Ω—É—é –ø–æ–∑–∏—Ü–∏—é —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π –ø–æ IOD"""
        try:
            if landmarks_3d is None or R_matrix is None:
                return landmarks_3d
            
            # 1. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ IOD (—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –≥–ª–∞–∑–∞–º–∏)
            left_eye_idx = 36  # –õ–µ–≤—ã–π –≥–ª–∞–∑
            right_eye_idx = 45  # –ü—Ä–∞–≤—ã–π –≥–ª–∞–∑
            iod = np.linalg.norm(landmarks_3d[right_eye_idx] - landmarks_3d[left_eye_idx])
            
            # –ó–∞—â–∏—Ç–∞ –æ—Ç –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å
            if iod < 1e-6:
                self.logger.warning("IOD —Å–ª–∏—à–∫–æ–º –º–∞–ª, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
                iod = 1.0
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
            normalized_landmarks = landmarks_3d / iod
            
            # 2. –ü—Ä–∏–º–µ–Ω—è–µ–º –æ–±—Ä–∞—Ç–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É –ø–æ–≤–æ—Ä–æ—Ç–∞ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ñ—Ä–æ–Ω—Ç–∞–ª—å–Ω–æ–π –ø–æ–∑–∏—Ü–∏–∏
            R_inv = R_matrix.T
            landmarks_frontal = np.zeros_like(normalized_landmarks)
            
            # 3. –ö–æ–º–ø–µ–Ω—Å–∞—Ü–∏—è –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã –¥–ª—è –∫–∞–∂–¥–æ–π —Ç–æ—á–∫–∏
            for i, point in enumerate(normalized_landmarks):
                # –í—ã—á–∏—Å–ª—è–µ–º Z-–∫–æ–º–ø–æ–Ω–µ–Ω—Ç—É –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã
                z_factor = max(1.0, 1.0 + point[2] * 0.1)  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤–ª–∏—è–Ω–∏–µ –¥–ª—è –±–æ–ª–µ–µ –≥–ª—É–±–æ–∫–∏—Ö —Ç–æ—á–µ–∫
                
                # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–æ–≤–æ—Ä–æ—Ç —Å —É—á–µ—Ç–æ–º –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã
                rotated_point = R_inv @ point
                
                # –ö–æ–º–ø–µ–Ω—Å–∏—Ä—É–µ–º –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã–µ –∏—Å–∫–∞–∂–µ–Ω–∏—è
                landmarks_frontal[i] = rotated_point * z_factor
            
            # 4. –°—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—è –≥–ª—É–±–∏–Ω—ã
            z_mean = np.mean(landmarks_frontal[:, 2])
            z_std = np.std(landmarks_frontal[:, 2])
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º Z-–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—É –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è –≤—ã–±—Ä–æ—Å–æ–≤
            if z_std > 0:
                landmarks_frontal[:, 2] = (landmarks_frontal[:, 2] - z_mean) / z_std
            
            self.logger.debug(f"–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω—ã landmarks –≤ —Ñ—Ä–æ–Ω—Ç–∞–ª—å–Ω—É—é –ø–æ–∑–∏—Ü–∏—é —Å IOD={iod:.4f}")
            return landmarks_frontal.astype(np.float32)
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ —Ñ—Ä–æ–Ω—Ç–∞–ª—å–Ω—É—é –ø–æ–∑–∏—Ü–∏—é: {e}")
            return landmarks_3d
    
    def correct_perspective_distortion(self, landmarks_3d: np.ndarray, s_scale: float, 
                                     yaw: float, pitch: float) -> np.ndarray:
        """–ò–°–ü–†–ê–í–õ–ï–ù–û: –£–ª—É—á—à–µ–Ω–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã—Ö –∏—Å–∫–∞–∂–µ–Ω–∏–π —Å —É—á–µ—Ç–æ–º –≥–ª—É–±–∏–Ω—ã –∏ –ø–æ–∑—ã"""
        try:
            if landmarks_3d is None:
                return landmarks_3d
            
            # 1. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –º–∞—Å—à—Ç–∞–±–∞
            corrected_landmarks = landmarks_3d * s_scale
            
            # 2. –†–∞—Å—á–µ—Ç —É–≥–ª–æ–≤ –≤ —Ä–∞–¥–∏–∞–Ω–∞—Ö
            yaw_rad = np.radians(abs(yaw))
            pitch_rad = np.radians(abs(pitch))
            
            # 3. –ë–∞–∑–æ–≤–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è –≥–ª—É–±–∏–Ω—ã
            z_mean = np.mean(corrected_landmarks[:, 2])
            z_std = np.std(corrected_landmarks[:, 2])
            
            # 4. –ö–æ–º–ø–µ–Ω—Å–∞—Ü–∏—è –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã –∏ –ø–æ–≤–æ—Ä–æ—Ç–∞ –¥–ª—è –∫–∞–∂–¥–æ–π —Ç–æ—á–∫–∏
            for i in range(len(corrected_landmarks)):
                point = corrected_landmarks[i]
                
                # –ö–æ–º–ø–µ–Ω—Å–∞—Ü–∏—è yaw (—Ä—ã—Å–∫–∞–Ω–∏–µ)
                if abs(yaw) > 5.0:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–µ–ª–∏–Ω–µ–π–Ω—É—é –∫–æ—Ä—Ä–µ–∫—Ü–∏—é –¥–ª—è –±–æ–ª—å—à–∏—Ö —É–≥–ª–æ–≤
                    x_factor = 1.0 / max(0.1, np.cos(yaw_rad))
                    z_offset = point[2] - z_mean
                    # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º X –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç Z-–ø–æ–∑–∏—Ü–∏–∏
                    x_correction = x_factor * (1.0 + 0.1 * abs(z_offset) / max(1e-6, z_std))
                    corrected_landmarks[i, 0] *= x_correction
                
                # –ö–æ–º–ø–µ–Ω—Å–∞—Ü–∏—è pitch (—Ç–∞–Ω–≥–∞–∂)
                if abs(pitch) > 5.0:
                    # –ê–Ω–∞–ª–æ–≥–∏—á–Ω–∞—è –Ω–µ–ª–∏–Ω–µ–π–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è –¥–ª—è Y
                    y_factor = 1.0 / max(0.1, np.cos(pitch_rad))
                    z_offset = point[2] - z_mean
                    y_correction = y_factor * (1.0 + 0.1 * abs(z_offset) / max(1e-6, z_std))
                    corrected_landmarks[i, 1] *= y_correction
                
                # –°—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—è Z-–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
                if z_std > 0:
                    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º Z, —Å–æ—Ö—Ä–∞–Ω—è—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –≥–ª—É–±–∏–Ω—ã
                    z_norm = (point[2] - z_mean) / z_std
                    # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å–∏–≥–º–æ–∏–¥–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –¥–∏–∞–ø–∞–∑–æ–Ω–∞
                    z_scaled = 2.0 / (1.0 + np.exp(-z_norm)) - 1.0
                    corrected_landmarks[i, 2] = z_mean + z_scaled * z_std
            
            return corrected_landmarks.astype(np.float32)
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã: {e}")
            return landmarks_3d
    
    def process_landmarks_3d(self, vertices: np.ndarray, name: str = "vertices") -> np.ndarray:
        """–ò–°–ü–†–ê–í–õ–ï–ù–û: –£–ª—É—á—à–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ 3D –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π"""
        if vertices is None:
            self.logger.error(f"{name} is None")
            return np.array([])  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π –º–∞—Å—Å–∏–≤ –≤–º–µ—Å—Ç–æ None
        
        try:
            # 1. –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞
            if len(vertices.shape) == 3 and vertices.shape[-1] == 1:
                vertices = np.squeeze(vertices, -1)
                self.logger.debug(f"–£–±—Ä–∞–Ω–æ –ª–∏—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ –∏–∑ {name}")
            
            # 2. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
            if len(vertices.shape) == 2:
                if vertices.shape[0] == 3 and vertices.shape[1] > vertices.shape[0]:
                    # –¢—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä—É–µ–º –∏–∑ (3, N) –≤ (N, 3)
                    result = vertices.T
                    self.logger.debug(f"–¢—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä–æ–≤–∞–Ω {name}: {vertices.shape} -> {result.shape}")
                elif vertices.shape[1] == 3:
                    # –£–∂–µ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ (N, 3)
                    result = vertices
                else:
                    self.logger.warning(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è —Ñ–æ—Ä–º–∞ {name}: {vertices.shape}")
                    return np.array([])
            else:
                self.logger.error(f"–ù–µ–≤–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–º–µ—Ä–µ–Ω–∏–π –≤ {name}: {len(vertices.shape)}")
                return np.array([])
            
            # 3. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
            # –¶–µ–Ω—Ç—Ä–∏—Ä—É–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –º–µ–¥–∏–∞–Ω—ã –¥–ª—è —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏ –∫ –≤—ã–±—Ä–æ—Å–∞–º
            centroid = np.median(result, axis=0)
            result = result - centroid
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –º–∞—Å—à—Ç–∞–± –ø–æ –º–µ–∂–≥–ª–∞–∑–Ω–æ–º—É —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é (IOD)
            left_eye_idx = 36  # –ò–Ω–¥–µ–∫—Å –ª–µ–≤–æ–≥–æ –≥–ª–∞–∑–∞
            right_eye_idx = 45  # –ò–Ω–¥–µ–∫—Å –ø—Ä–∞–≤–æ–≥–æ –≥–ª–∞–∑–∞
            
            if result.shape[0] > max(left_eye_idx, right_eye_idx):
                iod = np.linalg.norm(result[right_eye_idx] - result[left_eye_idx])
                if iod > 1e-6:
                    result = result / iod
                    self.logger.debug(f"–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –ø–æ IOD={iod:.4f}")
            
            # 4. –°—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—è Z-–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
            z_mean = np.mean(result[:, 2])
            z_std = np.std(result[:, 2])
            if z_std > 0:
                # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å–∏–≥–º–æ–∏–¥–Ω—É—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é –¥–ª—è Z-–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
                z_normalized = (result[:, 2] - z_mean) / z_std
                result[:, 2] = 2.0 / (1.0 + np.exp(-z_normalized)) - 1.0
            
            return result.astype(np.float32)
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {name}: {e}")
            return np.array([])

    def normalize_landmarks_with_pose_compensation(self, vertices, R_matrix, yaw, pitch, scale_factor=1.0):
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –≤–µ—Ä—à–∏–Ω—ã —Å –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏–µ–π –ø–æ–≤–æ—Ä–æ—Ç–∞ –≥–æ–ª–æ–≤—ã"""
        if vertices is None or len(vertices) == 0:
            return None
            
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        vertices = np.array(vertices)
        if vertices.shape[0] != 3 and vertices.shape[1] == 3:
            vertices = vertices.T
            
        # –¶–µ–Ω—Ç—Ä–∏—Ä—É–µ–º –≤–µ—Ä—à–∏–Ω—ã
        centroid = np.mean(vertices, axis=1, keepdims=True)
        vertices_centered = vertices - centroid
        
        # –ö–æ–º–ø–µ–Ω—Å–∞—Ü–∏—è –ø–æ–≤–æ—Ä–æ—Ç–∞ (–∏–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –º–∞—Ç—Ä–∏—Ü—É –ø–æ–≤–æ—Ä–æ—Ç–∞)
        R_inv = np.linalg.inv(R_matrix)
        vertices_unrotated = np.dot(R_inv, vertices_centered)
        
        # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
        if scale_factor != 1.0:
            vertices_unrotated *= scale_factor
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ z-–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–µ
        z_min, z_max = vertices_unrotated[2].min(), vertices_unrotated[2].max()
        if abs(z_max - z_min) > EPSILON:
            vertices_unrotated[2] = (vertices_unrotated[2] - z_min) / (z_max - z_min)
        
        return vertices_unrotated.T  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç–µ (N, 3)
    
    def project_vertices_to_2d(self, vertices_3d, img_size, camera_params=None):
        """–ü—Ä–æ–µ—Ü–∏—Ä—É–µ—Ç 3D –≤–µ—Ä—à–∏–Ω—ã –Ω–∞ 2D –ø–ª–æ—Å–∫–æ—Å—Ç—å —Å —É—á–µ—Ç–æ–º –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∫–∞–º–µ—Ä—ã"""
        if vertices_3d is None or len(vertices_3d) == 0:
            return None
            
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –æ–¥–Ω–æ—Ä–æ–¥–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
        vertices_3d = np.array(vertices_3d)
        if vertices_3d.shape[1] != 3:
            vertices_3d = vertices_3d.T
            
        # –î–æ–±–∞–≤–ª—è–µ–º –æ–¥–Ω–æ—Ä–æ–¥–Ω—É—é –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—É
        vertices_homo = np.hstack([vertices_3d, np.ones((vertices_3d.shape[0], 1))])
        
        if camera_params is not None and 'P' in camera_params:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–∞—Ç—Ä–∏—Ü—É –ø—Ä–æ–µ–∫—Ü–∏–∏ –∏–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∫–∞–º–µ—Ä—ã
            P = camera_params['P']
            vertices_2d = np.dot(vertices_homo, P.T)
        else:
            # –ü—Ä–æ—Å—Ç–∞—è –æ—Ä—Ç–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–µ–∫—Ü–∏—è
            vertices_2d = vertices_3d[:, :2]
            
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ –ø–∏–∫—Å–µ–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        w, h = img_size
        vertices_2d[:, 0] = np.clip(vertices_2d[:, 0] * w, 0, w-1)
        vertices_2d[:, 1] = np.clip(vertices_2d[:, 1] * h, 0, h-1)
        
        return vertices_2d

    def process_landmarks_3d_for_visualization(self, vertices: np.ndarray, roi_box: List = None) -> np.ndarray:
        """–ò–°–ü–†–ê–í–õ–ï–ù–û: –û–±—Ä–∞–±–æ—Ç–∫–∞ landmarks –ë–ï–ó –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏"""
        try:
            if vertices is None:
                return np.array([])
            # 1. –¢–æ–ª—å–∫–æ —Ç—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if len(vertices.shape) == 2:
                if vertices.shape[0] == 3 and vertices.shape[1] > vertices.shape[0]:
                    result = vertices.T  # (3, N) -> (N, 3)
                elif vertices.shape[1] == 3:
                    result = vertices  # –£–∂–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
                else:
                    return np.array([])
            else:
                return np.array([])
            # 2. –ù–ò–ö–ê–ö–û–ô –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏! Landmarks –¥–æ–ª–∂–Ω—ã –æ—Å—Ç–∞—Ç—å—Å—è –≤ –ø–∏–∫—Å–µ–ª—å–Ω—ã—Ö –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞—Ö
            # 3. –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç–æ–ª—å–∫–æ roi_box —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—é –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if roi_box and len(roi_box) >= 4:
                x1, y1, x2, y2 = roi_box[:4]
                if result.shape[0] > 0:
                    x_min, x_max = result[:, 0].min(), result[:, 0].max()
                    y_min, y_max = result[:, 1].min(), result[:, 1].max()
                    if x_min < x1 or x_max > x2 or y_min < y1 or y_max > y2:
                        # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –≤ –ø—Ä–µ–¥–µ–ª—ã roi_box
                        result[:, 0] = x1 + (result[:, 0] - x_min) * (x2 - x1) / (x_max - x_min)
                        result[:, 1] = y1 + (result[:, 1] - y_min) * (y2 - y1) / (y_max - y_min)
            return result.astype(np.float32)
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {vertices.shape if vertices is not None else 'None'}: {e}")
            return np.array([])

def setup_logging(level: str = "INFO") -> logging.Logger:
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
    logging.basicConfig(
        level=getattr(logging, level.upper()),
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('analysis.log', encoding='utf-8')
        ]
    )
    return logging.getLogger(__name__)

def debug_print(msg: str, level: str = "INFO"):
    """–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–ª–∞–¥–æ—á–Ω–æ–π –ø–µ—á–∞—Ç–∏"""
    if level == "ERROR":
        logging.error(msg)
    elif level == "WARN":
        logging.warning(msg)
    elif level == "DEBUG":
        logging.debug(msg)
    else:
        logging.info(msg)

def debug_array_info(arr: np.ndarray, name: str):
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–∞—Å—Å–∏–≤–µ"""
    if arr is None:
        debug_print(f"{name}: None", "WARN")
        return
    
    try:
        debug_print(
            f"{name}: shape={arr.shape}, dtype={arr.dtype}, "
            f"min={arr.min():.3f}, max={arr.max():.3f}, "
            f"mean={arr.mean():.3f}, std={arr.std():.3f}", "DEBUG"
        )
    except Exception as e:
        debug_print(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –º–∞—Å—Å–∏–≤–∞ {name}: {e}", "ERROR")



def get_landmarks_from_tddfa(tddfa, param_lst: List, roi_box_lst: List, dense: bool = False, for_visualization: bool = False) -> List[np.ndarray]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ landmarks –∏–∑ TDDFA: –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ - –±–µ–∑ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏, –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ - —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π"""
    debug_print(f"üéØ –ü–æ–ª—É—á–µ–Ω–∏–µ landmarks (dense={dense}, for_visualization={for_visualization}) –¥–ª—è {len(param_lst)} –ª–∏—Ü", "INFO")
    try:
        vertices_lst = tddfa.recon_vers(param_lst, roi_box_lst, dense_flag=dense)
        debug_print(f"–ü–æ–ª—É—á–µ–Ω–æ {len(vertices_lst)} –Ω–∞–±–æ—Ä–æ–≤ –≤–µ—Ä—à–∏–Ω", "INFO")
        processor = Enhanced3DFaceProcessor()
        processed_vertices = []
        for i, (vertices, roi_box, param) in enumerate(zip(vertices_lst, roi_box_lst, param_lst)):
            if not isinstance(vertices, np.ndarray):
                debug_print(f"vertices[{i}] –Ω–µ —è–≤–ª—è–µ—Ç—Å—è numpy array: {type(vertices)}", "ERROR")
                processed_vertices.append(None)
                continue
            if for_visualization:
                processed = processor.process_landmarks_3d_for_visualization(vertices, roi_box)
                processed_vertices.append(processed)
                debug_array_info(processed, f"Processed vertices[{i}] for visualization")
            else:
                params = processor.extract_pose_and_shape_parameters(param)
                R_matrix = params['R_matrix']
                yaw = params['yaw']
                pitch = params['pitch']
                normalized = processor.normalize_landmarks_with_pose_compensation(
                    vertices.T if vertices.shape[0] == 3 else vertices,
                    R_matrix, yaw, pitch
                )
                processed_vertices.append(normalized)
                debug_array_info(normalized, f"Normalized vertices[{i}]")
        return processed_vertices
    except Exception as e:
        debug_print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ landmarks: {e}", "ERROR")
        import traceback
        traceback.print_exc()
        return []

def darken_image(image: np.ndarray, factor: float = 0.3) -> np.ndarray:
    """–ó–∞—Ç–µ–º–Ω—è–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"""
    if len(image.shape) == 3 and image.shape[2] == 4:
        image = cv2.cvtColor(image, cv2.COLOR_BGRA2BGR)
        debug_print("–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ RGBA –≤ BGR", "DEBUG")
    
    black_overlay = np.zeros_like(image)
    return cv2.addWeighted(image, factor, black_overlay, 1 - factor, 0)

def calculate_embedding_similarity(embedding1: List[float], embedding2: List[float]) -> float:
    """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞"""
    try:
        if len(embedding1) != len(embedding2):
            debug_print(f"–†–∞–∑–Ω–∞—è –¥–ª–∏–Ω–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {len(embedding1)} vs {len(embedding2)}", "WARN")
            return 0.0
        
        emb1 = np.array(embedding1, dtype=np.float32)
        emb2 = np.array(embedding2, dtype=np.float32)
        
        norm1 = np.linalg.norm(emb1)
        norm2 = np.linalg.norm(emb2)
        
        if norm1 < EPSILON or norm2 < EPSILON:
            return 0.0
        
        emb1 = emb1 / norm1
        emb2 = emb2 / norm2
        
        similarity = np.dot(emb1, emb2)
        return max(0.0, min(1.0, float(similarity)))
        
    except Exception as e:
        debug_print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–∏ —Å—Ö–æ–¥—Å—Ç–≤–∞: {e}", "ERROR")
        return 0.0

def determine_pose_side(pose_type: str, yaw: float) -> str:
    if pose_type == "frontal":
        return "front"
    else:
        return "right" if yaw > 0 else "left"

def calculate_real_deviation(measured: float, ideal: float) -> float:
    """–†–∞—Å—á–µ—Ç —Ä–µ–∞–ª—å–Ω–æ–≥–æ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –æ—Ç –∏–¥–µ–∞–ª—å–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è"""
    if abs(ideal) < EPSILON:
        return 0.0
    return abs(measured - ideal) / ideal * 100.0

def process_single_face_enhanced(face_idx: int, landmarks_3d: np.ndarray, params: np.ndarray,
                               roi_box: List, modules: Dict, insightface_embedding: List[float],
                               img: np.ndarray, processor_3d: Enhanced3DFaceProcessor) -> Dict:
    """–ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞"""
    try:
        if landmarks_3d is None:
            logging.warning(f"landmarks_3d is None –¥–ª—è –ª–∏—Ü–∞ {face_idx}")
            return {}

        # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∑—ã –∏ –∞–Ω–∞–ª–∏–∑    
        pose_params = processor_3d.extract_pose_and_shape_parameters(params)
        if not pose_params:
            logging.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∑—ã –¥–ª—è –ª–∏—Ü–∞ {face_idx}")
            return {}

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ø–æ–∑—ã
        pose_type = modules['frontal'].marquardt_mask.classify_pose(
            pose_params['yaw'], pose_params['pitch'], pose_params['roll']
        )
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –±–∞–∑–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        face_result = {
            "detection": {
                "face_index": face_idx,
                "bounding_box": roi_box,
                "confidence": 1.0
            },
            "pose": {
                "type": pose_type,
                "angles": {
                    "pitch": float(pose_params['pitch']),
                    "yaw": float(pose_params['yaw']),
                    "roll": float(pose_params['roll'])
                }
            },
            "landmarks": {
                "raw_3d": landmarks_3d.tolist() if isinstance(landmarks_3d, np.ndarray) else [],
                "normalized_3d": []
            },
            "embedding": insightface_embedding
        }

        # –í—ã–ø–æ–ª–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑
        analysis_module = modules.get(pose_type)
        if analysis_module is None:
            logging.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω –º–æ–¥—É–ª—å –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è —Ç–∏–ø–∞ –ø–æ–∑—ã {pose_type}")
            return face_result

        try:
            # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
            analysis_result = analysis_module.analyze(
                landmarks_3d,
                pitch=float(pose_params['pitch']),
                yaw=float(pose_params['yaw']),
                roll=float(pose_params['roll']),
                alpha_shp=pose_params['alpha_shp'],
                alpha_exp=pose_params['alpha_exp'],
                R_matrix=pose_params['R_matrix'],
                t_vec=pose_params['t_vec'],
                s_scale=float(pose_params['s_scale'])
            )

            if not analysis_result:
                logging.warning(f"–ê–Ω–∞–ª–∏–∑ –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –ª–∏—Ü–∞ {face_idx}")
                return face_result

            # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏–∑–º–µ—Ä–µ–Ω–∏—è
            validated_result = {}
            for category in ['raw_measurements', 'angular_metrics', 'proportion_metrics',
                           'skull_metrics', 'symmetry_metrics', 'anomaly_detection',
                           'stabilization_info']:
                category_data = analysis_result.get(category, {})
                if not isinstance(category_data, dict):
                    logging.warning(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {category}: {type(category_data)}")
                    continue

                validated_category = {}
                for key, value in category_data.items():
                    if isinstance(value, (np.floating, np.integer)):
                        validated_category[key] = float(value)
                    elif isinstance(value, dict):
                        validated_category[key] = {
                            k: float(v) if isinstance(v, (np.floating, np.integer)) else v
                            for k, v in value.items()
                        }
                    else:
                        validated_category[key] = value

                validated_result[category] = validated_category

            # –û–±–Ω–æ–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
            face_result.update(validated_result)

        except Exception as analysis_error:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –ª–∏—Ü–∞ {face_idx}: {str(analysis_error)}")
            traceback.print_exc()

        return face_result

    except Exception as e:
        logging.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ process_single_face_enhanced: {e}")
        traceback.print_exc()
        return {}

def generate_visualizations(img: np.ndarray, param_lst: List, roi_box_lst: List,
                          landmarks_3d_lst: List[np.ndarray], tddfa, base_name: str,
                          opt: str, selected_viz: Optional[List[str]] = None) -> Dict:
    """–ò–°–ü–†–ê–í–õ–ï–ù–û: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π —Å–æ–≥–ª–∞—Å–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ 3DDFA_V2"""
    generated_files = {}
    if opt == 'none':
        debug_print("–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –æ—Ç–∫–ª—é—á–µ–Ω—ã", "INFO")
        return generated_files
    if opt == 'all':
        visualizations = ['2d_sparse', '2d_dense', '3d', 'depth', 'pncc', 'obj']
        debug_print("–°–¢–ê–¢–£–°: –û–ø—Ü–∏—è 'all' –∞–∫—Ç–∏–≤–Ω–∞, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤—Å–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏.", "INFO")
    elif opt == 'selected':
        visualizations = selected_viz or []
        if not visualizations:
            debug_print("–ù–∏ –æ–¥–Ω–æ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω–µ –≤—ã–±—Ä–∞–Ω–æ (--opt selected)", "WARN")
            return generated_files
        debug_print(f"–°–¢–ê–¢–£–°: –û–ø—Ü–∏—è 'selected' –∞–∫—Ç–∏–≤–Ω–∞: {visualizations}", "INFO")
    else:
        visualizations = [opt]
    ver_lst_dense = []
    if any(viz in ['2d_dense', '3d', 'depth', 'pncc', 'obj'] for viz in visualizations):
        try:
            ver_lst_dense = tddfa.recon_vers(param_lst, roi_box_lst, dense_flag=True)
            debug_print(f"–ü–æ–ª—É—á–µ–Ω—ã RAW –ø–ª–æ—Ç–Ω—ã–µ –≤–µ—Ä—à–∏–Ω—ã –¥–ª—è {len(ver_lst_dense)} –ª–∏—Ü", "DEBUG")
        except Exception as e:
            debug_print(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–ª–æ—Ç–Ω—ã—Ö –≤–µ—Ä—à–∏–Ω: {e}", "ERROR")
            ver_lst_dense = []
    original_wfp = f'examples/results/{base_name}_original.jpg'
    cv2.imwrite(original_wfp, img)
    generated_files["original_image"] = original_wfp
    for viz_type in visualizations:
        try:
            wfp = f'examples/results/{base_name}_{viz_type}'
            if viz_type == 'obj':
                wfp += '.obj'
            else:
                wfp += '.jpg'
            if viz_type != 'obj':
                img_darkened = darken_image(img.copy(), factor=0.3)
            else:
                img_darkened = img.copy()
            if viz_type == '2d_sparse':
                # –ü–æ–ª—É—á–∞–µ–º —Å–≤–µ–∂–∏–µ landmarks –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
                sparse_landmarks_viz = get_landmarks_from_tddfa(tddfa, param_lst, roi_box_lst, dense=False, for_visualization=True)
                _generate_2d_sparse_visualization(img_darkened, sparse_landmarks_viz, wfp, generated_files, base_name)
            elif viz_type == '2d_dense':
                # –ü–æ–ª—É—á–∞–µ–º —Å–≤–µ–∂–∏–µ landmarks –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
                dense_landmarks_viz = get_landmarks_from_tddfa(tddfa, param_lst, roi_box_lst, dense=True, for_visualization=True)
                _generate_2d_dense_visualization(img_darkened, dense_landmarks_viz, wfp, generated_files, base_name, param_lst)
            elif viz_type == '3d':
                if ver_lst_dense and len(ver_lst_dense) > 0:
                    render(img_darkened, ver_lst_dense, tddfa.tri, alpha=1.0, wfp=wfp)
                    debug_print(f'3D render saved to {wfp}', "INFO")
                    generated_files["3d_render_image"] = wfp
            elif viz_type == 'depth':
                if ver_lst_dense and len(ver_lst_dense) > 0:
                    depth(img_darkened, ver_lst_dense, tddfa.tri, wfp=wfp, with_bg_flag=True)
                    debug_print(f'Depth map saved to {wfp}', "INFO")
                    generated_files["depth_map_image"] = wfp
            elif viz_type == 'pncc':
                if ver_lst_dense and len(ver_lst_dense) > 0:
                    pncc(img_darkened, ver_lst_dense, tddfa.tri, wfp=wfp, with_bg_flag=True)
                    debug_print(f'PNCC map saved to {wfp}', "INFO")
                    generated_files["pncc_map_image"] = wfp
            elif viz_type == 'obj':
                if ver_lst_dense and len(ver_lst_dense) > 0:
                    ser_to_obj(img, ver_lst_dense, tddfa.tri, height=img.shape[0], wfp=wfp)
                    debug_print(f'OBJ model saved to {wfp}', "INFO")
                    generated_files["obj_model"] = wfp
        except Exception as e:
            debug_print(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ {viz_type}: {e}", "ERROR")
            import traceback
            traceback.print_exc()
    return generated_files

def _generate_2d_sparse_visualization(img_darkened: np.ndarray, landmarks_3d_lst: List[np.ndarray],
                                    wfp: str, generated_files: Dict, base_name: str):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è 2D sparse landmarks –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏"""
    # –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å–æ–≥–ª–∞—Å–Ω–æ dlib 68-point model
    connections = {
        'jawline': [(i, i+1) for i in range(16)],
        'right_eyebrow': [(i, i+1) for i in range(17, 21)],
        'left_eyebrow': [(i, i+1) for i in range(22, 26)],
        'nose_bridge': [(i, i+1) for i in range(27, 30)],
        'nose_lower': [(31, 32), (32, 33), (33, 34), (34, 35), (35, 31)],
        'right_eye': [(36, 37), (37, 38), (38, 39), (39, 40), (40, 41), (41, 36)],
        'left_eye': [(42, 43), (43, 44), (44, 45), (45, 46), (46, 47), (47, 42)],
        'outer_lips': [(48, 49), (49, 50), (50, 51), (51, 52), (52, 53),
                       (53, 54), (54, 55), (55, 56), (56, 57), (57, 58), (58, 59), (59, 48)],
        'inner_lips': [(60, 61), (61, 62), (62, 63), (63, 64), (64, 65), (65, 66), (66, 67), (67, 60)]
    }
    
    img_viz = img_darkened.copy()
    h, w = img_viz.shape[:2]
    point_color = (255, 255, 255)      # –ë–µ–ª—ã–π
    line_color = (0, 0, 255)           # –ö—Ä–∞—Å–Ω—ã–π
    text_color = (255, 255, 255)           # –ö—Ä–∞—Å–Ω—ã–π

    for face_landmarks in landmarks_3d_lst:
        if face_landmarks is None or len(face_landmarks) < 68:
            continue
        
        points_2d = face_landmarks[:68, :2].astype(np.int32)
        
        # –†–∏—Å–æ–≤–∞–Ω–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π (–∫—Ä–∞—Å–Ω—ã–µ –ª–∏–Ω–∏–∏)
        for region_name, point_pairs in connections.items():
            for p1_idx, p2_idx in point_pairs:
                if p1_idx < len(points_2d) and p2_idx < len(points_2d):
                    pt1 = tuple(points_2d[p1_idx])
                    pt2 = tuple(points_2d[p2_idx])
                    if (0 <= pt1[0] < w and 0 <= pt1[1] < h and
                        0 <= pt2[0] < w and 0 <= pt2[1] < h):
                        cv2.line(img_viz, pt1, pt2, line_color, 1, cv2.LINE_AA)
        
        # –†–∏—Å–æ–≤–∞–Ω–∏–µ —Ç–æ—á–µ–∫ (–±–µ–ª—ã–µ) –∏ –Ω–æ–º–µ—Ä–æ–≤ (–∫—Ä–∞—Å–Ω—ã–µ)
        for i, (x, y) in enumerate(points_2d):
            if 0 <= x < w and 0 <= y < h:
                cv2.circle(img_viz, (int(x), int(y)), 1, point_color, -1, cv2.LINE_AA)
                cv2.putText(img_viz, str(i), (int(x)+3, int(y)-3), cv2.FONT_HERSHEY_SIMPLEX, 
                            0.35, text_color, 1, cv2.LINE_AA)
    
    cv2.imwrite(wfp, img_viz)
    debug_print(f'2D sparse landmarks visualization saved to {wfp}', "INFO")
    generated_files["landmarks_2d_sparse"] = wfp

def _generate_2d_dense_visualization(img_darkened: np.ndarray, ver_lst_dense: List[np.ndarray],
                                   wfp: str, generated_files: Dict, base_name: str,
                                   param_lst: Optional[List] = None):
    """–ò–°–ü–†–ê–í–õ–ï–ù–û: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è 2D dense –±–µ–∑ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏"""
    if not ver_lst_dense or len(ver_lst_dense) == 0:
        debug_print(f"–°–¢–ê–¢–£–°: –ü—Ä–æ–ø—É—Å–∫ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ 2d_dense –¥–ª—è {base_name} - –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö", "WARN")
        return
    green_color = (0, 255, 0)
    point_thickness = 1
    img_dense_viz = img_darkened.copy()
    h, w = img_dense_viz.shape[:2]
    faces_drawn = 0
    for face_idx, face_vertices in enumerate(ver_lst_dense):
        if face_vertices is not None:
            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –∏—Å—Ö–æ–¥–Ω—ã–µ (—Å—ã—Ä—ã–µ) landmarks –±–µ–∑ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
                if face_vertices.shape[0] == 3:
                    points_3d = face_vertices.T
                else:
                    points_3d = face_vertices
                points_2d = points_3d[:, :2].astype(np.int32)
                valid_mask = ((points_2d[:, 0] >= 0) & (points_2d[:, 0] < w) &
                             (points_2d[:, 1] >= 0) & (points_2d[:, 1] < h))
                points_2d_filtered = points_2d[valid_mask]
                if len(points_2d_filtered) > 0:
                    faces_drawn += 1
                    debug_print(f"Dense visualization: {len(points_2d_filtered)} valid points", "DEBUG")
                    if points_3d.shape[1] >= 3:
                        z_values = points_3d[valid_mask, 2]
                        z_min, z_max = z_values.min(), z_values.max()
                        z_range = z_max - z_min
                        for point_idx, (x, y) in enumerate(points_2d_filtered):
                            if z_range > 1e-6:
                                # intensity: –±–ª–∏–∂–Ω–∏–µ –∫ –∫–∞–º–µ—Ä–µ (z_min) ‚Äî 255, –¥–∞–ª—å–Ω–∏–µ (z_max) ‚Äî 80
                                intensity = int(255 + 255 * (1 - (z_values[point_idx] - z_min) / z_range))  # 80..255
                                point_color = (0, intensity, 0)
                            else:
                                point_color = green_color
                            size = int(0.3 + 0.5 * ((z_values[point_idx] - z_min) / z_range))  # —Ä–∞–∑–º–µ—Ä: –¥–∞–ª—å–Ω–∏–µ –∫—Ä—É–ø–Ω–µ–µ
                            cv2.circle(img_dense_viz, (x, y), size, point_color, -1)
                    else:
                        for x, y in points_2d_filtered:
                            cv2.circle(img_dense_viz, (x, y), point_thickness, green_color, -1)
            except Exception as e:
                debug_print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ dense face {face_idx}: {e}", "ERROR")
                continue
    if faces_drawn > 0:
        cv2.imwrite(wfp, img_dense_viz)
        debug_print(f'2D dense landmarks visualization saved to {wfp}', "INFO")
        generated_files["2d_dense_landmarks_image"] = wfp
    else:
        debug_print(f"–°–¢–ê–¢–£–°: –ü—Ä–æ–ø—É—Å–∫ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ 2d_dense –¥–ª—è {base_name} - –Ω–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö —Ç–æ—á–µ–∫", "WARN")

def compare_faces_embeddings(all_analysis_results: Dict) -> Dict:
    """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –ª–∏—Ü"""
    debug_print("üîÑ –ó–∞–ø—É—Å–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –ª–∏—Ü...", "INFO")
    
    face_comparisons = {}
    image_names = list(all_analysis_results.keys())
    
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ–∂–¥—É –≤—Å–µ–º–∏ –ø–∞—Ä–∞–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    for i in range(len(image_names)):
        img_name1 = image_names[i]
        faces_data1 = all_analysis_results[img_name1]["faces_data"]
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤–Ω—É—Ç—Ä–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        for face_idx1 in range(len(faces_data1)):
            for face_idx2 in range(face_idx1 + 1, len(faces_data1)):
                embedding1 = faces_data1[face_idx1].get("insightface_embedding", [])
                embedding2 = faces_data1[face_idx2].get("insightface_embedding", [])
                
                if embedding1 and embedding2:
                    similarity = calculate_embedding_similarity(embedding1, embedding2)
                    comparison_key = f"{img_name1}_face{face_idx1}_vs_{img_name1}_face{face_idx2}"
                    
                    face_comparisons[comparison_key] = {
                        "embedding_similarity": round(similarity, 6),
                        "likely_same_person": bool(similarity > INSIGHT_FACE_THRESHOLD),
                        "confidence": round(similarity, 6),
                        "comparison_type": "intra_image"
                    }
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ–∂–¥—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
        for j in range(i + 1, len(image_names)):
            img_name2 = image_names[j]
            faces_data2 = all_analysis_results[img_name2]["faces_data"]
            
            for face_idx1, face1 in enumerate(faces_data1):
                embedding1 = face1.get("insightface_embedding", [])
                if not embedding1:
                    continue
                
                for face_idx2, face2 in enumerate(faces_data2):
                    embedding2 = face2.get("insightface_embedding", [])
                    if not embedding2:
                        continue
                    
                    similarity = calculate_embedding_similarity(embedding1, embedding2)
                    comparison_key = f"{img_name1}_face{face_idx1}_vs_{img_name2}_face{face_idx2}"
                    
                    face_comparisons[comparison_key] = {
                        "embedding_similarity": round(similarity, 6),
                        "likely_same_person": bool(similarity > INSIGHT_FACE_THRESHOLD),
                        "confidence": round(similarity, 6),
                        "comparison_type": "inter_image"
                    }
    
    debug_print(f"‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤. –ù–∞–π–¥–µ–Ω–æ {len(face_comparisons)} —Å—Ä–∞–≤–Ω–µ–Ω–∏–π.", "SUCCESS")
    return face_comparisons

def analyze_identity_groups(face_comparisons: Dict) -> Dict:
    """–ê–Ω–∞–ª–∏–∑ –≥—Ä—É–ø–ø –∏–¥–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Union-Find"""
    debug_print("üîÑ –ê–Ω–∞–ª–∏–∑ –≥—Ä—É–ø–ø –∏–¥–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏...", "INFO")
    
    uf = UnionFind()
    
    # –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ —Å–≤—è–∑–µ–π
    for key, data in face_comparisons.items():
        if data["likely_same_person"]:
            parts = key.split("_vs_")
            face1_id = parts[0]
            face2_id = parts[1]
            uf.union(face1_id, face2_id)
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∫–æ—Ä–Ω—è–º
    groups = {}
    for key in face_comparisons:
        parts = key.split("_vs_")
        for face_id in parts:
            root = uf.find(face_id)
            if root not in groups:
                groups[root] = set()
            groups[root].add(face_id)

    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    identity_analysis = {
        "identity_groups": [],
        "total_unique_identities": 0,
        "summary_by_image": {}
    }
    
    for group_faces in groups.values():
        if len(group_faces) > 1:
            group_entry = {
                "group_id": f"identity_{len(identity_analysis['identity_groups']) + 1}",
                "faces": sorted(list(group_faces)),
                "num_faces": len(group_faces)
            }
            
            identity_analysis["identity_groups"].append(group_entry)
            identity_analysis["total_unique_identities"] += 1
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å–≤–æ–¥–∫—É –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º
            for face_id in group_faces:
                img_name = face_id.split("_face")[0]
                identity_analysis["summary_by_image"].setdefault(img_name, 0)
                identity_analysis["summary_by_image"][img_name] += 1
    
    debug_print(f"‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω –∞–Ω–∞–ª–∏–∑ –∏–¥–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏. –ù–∞–π–¥–µ–Ω–æ {len(identity_analysis['identity_groups'])} –≥—Ä—É–ø–ø –∏–¥–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏.", "SUCCESS")
    return identity_analysis

def calculate_global_statistics(all_analysis_results: Dict) -> Dict:
    """–†–∞—Å—á–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
    debug_print("üîÑ –†–∞—Å—á–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏...", "INFO")
    
    global_statistics = {
        "pose_angles": {"pitch": [], "yaw": [], "roll": []},
        "biometric_metrics": {}
    }
    
    # –ê–≥—Ä–µ–≥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
    for img_name, img_data in all_analysis_results.items():
        for face_data in img_data["faces_data"]:
            try:
                # –£–≥–ª—ã –ø–æ–∑—ã
                pose_angles = face_data["pose"]["angles"]
                global_statistics["pose_angles"]["pitch"].append(pose_angles["pitch"])
                global_statistics["pose_angles"]["yaw"].append(pose_angles["yaw"])
                global_statistics["pose_angles"]["roll"].append(pose_angles["roll"])
                
                # –ë–∏–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏
                biometric_analysis = face_data.get("biometric_analysis", {})
                for category, metrics in biometric_analysis.items():
                    if isinstance(metrics, dict):
                        for metric_name, metric_data in metrics.items():
                            if isinstance(metric_data, dict):
                                for value_type, value in metric_data.items():
                                    if isinstance(value, (int, float)) and not np.isnan(value):
                                        key = f"{category}_{metric_name}_{value_type}"
                                        global_statistics["biometric_metrics"].setdefault(key, []).append(value)
                                        
            except Exception as e:
                debug_print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –ª–∏—Ü–∞ –≤ {img_name}: {e}", "ERROR")
                continue
    
    # –†–∞—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    calculated_stats = {}
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —É–≥–ª–∞–º –ø–æ–∑—ã
    for angle_type, values in global_statistics["pose_angles"].items():
        if values:
            calculated_stats[f"pose_{angle_type}"] = {
                "mean": float(np.mean(values)),
                "std": float(np.std(values)),
                "min": float(np.min(values)),
                "max": float(np.max(values))
            }
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –±–∏–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–º –º–µ—Ç—Ä–∏–∫–∞–º
    for metric_name, values in global_statistics["biometric_metrics"].items():
        if values and len(values) > 1:
            calculated_stats[metric_name] = {
                "mean": float(np.mean(values)),
                "std": float(np.std(values)),
                "min": float(np.min(values)),
                "max": float(np.max(values))
            }
    
    debug_print("‚úÖ –ì–ª–æ–±–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ.", "SUCCESS")
    return calculated_stats

def print_analysis_conclusions(summary_report: Dict):
    """–ü–µ—á–∞—Ç—å –≤—ã–≤–æ–¥–æ–≤ –∞–Ω–∞–ª–∏–∑–∞"""
    debug_print("üìä –ü–µ—á–∞—Ç—å –∫–ª—é—á–µ–≤—ã—Ö –≤—ã–≤–æ–¥–æ–≤ –∞–Ω–∞–ª–∏–∑–∞...", "INFO")
    
    analysis_summary = summary_report.get("analysis_summary", {})
    face_comparisons = summary_report.get("face_comparisons", {})
    identity_analysis = summary_report.get("identity_analysis", {})
    statistical_summary = summary_report.get("statistical_summary", {})
    
    print("\n" + "="*60)
    print("üîç –ö–õ–Æ–ß–ï–í–´–ï –í–´–í–û–î–´ –ê–ù–ê–õ–ò–ó–ê")
    print("="*60)
    
    print(f"\nüìä –û–±—â–∏–µ —Å–≤–µ–¥–µ–Ω–∏—è:")
    print(f"  ‚Ä¢ –í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {analysis_summary.get('total_images_processed', 0)}")
    print(f"  ‚Ä¢ –í—Å–µ–≥–æ –ª–∏—Ü –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ: {analysis_summary.get('total_faces_detected', 0)}")
    print(f"  ‚Ä¢ –í—Å–µ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏–π –≤—ã–ø–æ–ª–Ω–µ–Ω–æ: {len(face_comparisons)}")
    
    if identity_analysis.get("total_unique_identities", 0) > 0:
        print(f"\nüë• –ì—Ä—É–ø–ø—ã –∏–¥–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏:")
        for group in identity_analysis["identity_groups"]:
            faces_str = ", ".join(group['faces'])
            print(f"  ‚Ä¢ {group['group_id']}: {group['num_faces']} –ª–∏—Ü - {faces_str}")
    else:
        print("\n‚úÖ –í—Å–µ –ª–∏—Ü–∞ —É–Ω–∏–∫–∞–ª—å–Ω—ã")
    
    if statistical_summary:
        print(f"\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º –º–µ—Ç—Ä–∏–∫–∞–º:")
        key_metrics = [
            ("pose_yaw", "–ü–æ–≤–æ—Ä–æ—Ç –≥–æ–ª–æ–≤—ã (yaw)"),
            ("pose_pitch", "–ù–∞–∫–ª–æ–Ω –≥–æ–ª–æ–≤—ã (pitch)")
        ]
        
        for metric_key, metric_name in key_metrics:
            if metric_key in statistical_summary:
                stats = statistical_summary[metric_key]
                print(f"  ‚Ä¢ {metric_name}:")
                print(f"    - –°—Ä–µ–¥–Ω–µ–µ: {stats['mean']:.3f}")
                print(f"    - –î–∏–∞–ø–∞–∑–æ–Ω: {stats['min']:.3f} - {stats['max']:.3f}")
    
    print("\n" + "="*60)
    print("‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù –£–°–ü–ï–®–ù–û")
    print("="*60)

def validate_input_path(path: str) -> Tuple[bool, List[str]]:
    """–í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω–æ–≥–æ –ø—É—Ç–∏ –∏ –ø–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤"""
    path_obj = Path(path)
    
    if not path_obj.exists():
        return False, []
    
    if path_obj.is_file():
        if path_obj.suffix.lower() in SUPPORTED_FORMATS:
            return True, [str(path_obj)]
        else:
            debug_print(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {path_obj.suffix}", "ERROR")
            return False, []
    elif path_obj.is_dir():
        image_files = []
        for ext in SUPPORTED_FORMATS:
            image_files.extend(path_obj.glob(f"*{ext}"))
            image_files.extend(path_obj.glob(f"*{ext.upper()}"))
        image_files = [str(f) for f in image_files]
        
        if not image_files:
            debug_print(f"–ù–µ –Ω–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ {path}", "ERROR")
            return False, []
        
        return True, sorted(image_files)
    
    return False, []

def main(args):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    logger = setup_logging("DEBUG" if args.verbose else "INFO")
    debug_print("üöÄ –£–õ–£–ß–®–ï–ù–ù–ê–Ø –°–ò–°–¢–ï–ú–ê –ê–ù–ê–õ–ò–ó–ê –õ–ò–¶ –° –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø–ú–ò", "INFO")
    debug_print("–ó–∞–ø—É—Å–∫ —Å–∏—Å—Ç–µ–º—ã –∞–Ω–∞–ª–∏–∑–∞", "INFO")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    os.makedirs('examples/results', exist_ok=True)
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω–æ–≥–æ –ø—É—Ç–∏
    is_valid, image_files = validate_input_path(args.img_fp)
    if not is_valid:
        debug_print(f"–ù–µ–≤–µ—Ä–Ω—ã–π –ø—É—Ç—å –∏–ª–∏ –Ω–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {args.img_fp}", "ERROR")
        sys.exit(-1)
    
    debug_print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(image_files)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏", "SUCCESS")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    debug_print("üìã –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏...", "DEBUG")
    try:
        cfg = yaml.load(open(args.config), Loader=yaml.SafeLoader)
        debug_print(f"‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {args.config}", "SUCCESS")
    except Exception as e:
        debug_print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é: {e}", "ERROR")
        sys.exit(-1)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è TDDFA
    debug_print("ü§ñ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è TDDFA...", "DEBUG")
    try:
        if args.onnx:
            os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'
            os.environ['OMP_NUM_THREADS'] = '4'
            from FaceBoxes.FaceBoxes_ONNX import FaceBoxes_ONNX
            from TDDFA_ONNX import TDDFA_ONNX
            face_boxes = FaceBoxes_ONNX()
            tddfa = TDDFA_ONNX(**cfg)
        else:
            gpu_mode = args.mode == 'gpu'
            tddfa = TDDFA(gpu_mode=gpu_mode, **cfg)
        debug_print("‚úÖ TDDFA –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ", "SUCCESS")
    except Exception as e:
        debug_print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å TDDFA: {e}", "ERROR")
        sys.exit(-1)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è InsightFace
    debug_print("üëÅÔ∏è –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è InsightFace...", "DEBUG")
    try:
        providers = ['CUDAExecutionProvider', 'CPUExecutionProvider'] if args.mode == 'gpu' else ['CPUExecutionProvider']
        ctx = 0 if args.mode == 'gpu' else -1
        app = FaceAnalysis(name='buffalo_l', providers=providers)
        app.prepare(ctx_id=ctx, det_size=(640, 640))
        debug_print("‚úÖ InsightFace –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ", "SUCCESS")
    except Exception as e:
        debug_print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å InsightFace: {e}", "ERROR")
        sys.exit(-1)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥—É–ª–µ–π –∞–Ω–∞–ª–∏–∑–∞
    debug_print("üî¨ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥—É–ª–µ–π –∞–Ω–∞–ª–∏–∑–∞...", "DEBUG")
    modules = {
        'frontal': FrontalAnalysisModule(),
        'frontal_edge': FrontalEdgeAnalysisModule(),
        'semi_profile': SemiProfileAnalysisModule(),
        'profile': ProfileAnalysisModule()
    }
    debug_print("‚úÖ –ú–æ–¥—É–ª–∏ –∞–Ω–∞–ª–∏–∑–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã", "SUCCESS")
    
    # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É–ª—É—á—à–µ–Ω–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    processor_3d = Enhanced3DFaceProcessor()
    
    # –•—Ä–∞–Ω–∏–ª–∏—â–µ –≤—Å–µ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    all_analysis_results = {}
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    for img_idx, img_path in enumerate(image_files):
        debug_print(f'\nüì∏ –û–ë–†–ê–ë–û–¢–ö–ê {img_idx+1}/{len(image_files)}: {img_path}', "INFO")
        
        try:
            # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            debug_print("–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...", "DEBUG")
            img = cv2.imread(img_path)
            if img is None:
                debug_print(f'–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {img_path}', "ERROR")
                continue
            
            debug_print(f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {img.shape}", "SUCCESS")
            base_name = os.path.splitext(os.path.basename(img_path))[0]
            
            # –î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü —Å –ø–æ–º–æ—â—å—é InsightFace
            debug_print("üëÅÔ∏è –î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü —Å –ø–æ–º–æ—â—å—é InsightFace...", "DEBUG")
            faces_insight = app.get(img)
            n_faces = len(faces_insight)
            debug_print(f'‚úÖ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {n_faces} –ª–∏—Ü', "SUCCESS")
            
            if n_faces == 0:
                debug_print(f'–õ–∏—Ü–∞ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã –≤ {img_path}', "WARN")
                continue
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ bounding boxes —Å –ø–æ–º–æ—â—å—é TDDFA
            debug_print("üì¶ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ bounding boxes –¥–ª—è TDDFA...", "DEBUG")
            boxes_for_tddfa = []
            embeddings_list = []
            h, w = img.shape[:2]
            
            for i, face in enumerate(faces_insight):
                x1, y1, x2, y2 = face.bbox.astype(float)
                # –ö–ª–∏–ø–ø–∏–Ω–≥ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
                x1, y1 = max(0, x1), max(0, y1)
                x2, y2 = min(w - 1, x2), min(h - 1, y2)
                boxes_for_tddfa.append([np.float32(x1), np.float32(y1),
                                      np.float32(x2), np.float32(y2), 1.0])
                embeddings_list.append(face.embedding.tolist())
                debug_print(f"–õ–∏—Ü–æ {i}: bbox=[{x1:.1f},{y1:.1f},{x2:.1f},{y2:.1f}], embedding_len={len(face.embedding)}", "DEBUG")
            
            # 3D —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è —Å –ø–æ–º–æ—â—å—é TDDFA
            debug_print("üß† 3D —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è —Å –ø–æ–º–æ—â—å—é TDDFA...", "DEBUG")
            param_lst, roi_box_lst = tddfa(img, boxes_for_tddfa)
            debug_print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω—ã –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è {len(param_lst)} –ª–∏—Ü", "SUCCESS")
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ landmarks
            landmarks_3d_lst = get_landmarks_from_tddfa(tddfa, param_lst, roi_box_lst, dense=False)
            debug_print(f'‚úÖ 3D —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –¥–ª—è {len(landmarks_3d_lst)} –ª–∏—Ü', "SUCCESS")
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ –ª–∏—Ü–∞
            faces_data = []
            for face_idx, (landmarks_3d_original, params, roi_box, embedding) in enumerate(
                zip(landmarks_3d_lst, param_lst, roi_box_lst, embeddings_list)
            ):
                debug_print(f'üé≠ –û–±—Ä–∞–±–æ—Ç–∫–∞ –ª–∏—Ü–∞ {face_idx}...', "INFO")
                
                # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º–∏
                face_result = process_single_face_enhanced(
                    face_idx, landmarks_3d_original, params, roi_box, modules,
                    embedding, img, processor_3d
                )
                
                faces_data.append(face_result)
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π
            generated_files = generate_visualizations(
                img, param_lst, roi_box_lst, landmarks_3d_lst, tddfa, base_name, args.opt
            )
            
            # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            image_result = {
                "image_info": {
                    "path": str(img_path),
                    "name": base_name,
                    "dimensions": {"width": img.shape[1], "height": img.shape[0]},
                    "faces_detected_count": len(faces_data),
                    "processing_timestamp": str(np.datetime64('now')),
                    "analyzer_version": "3DDFA_V2_Enhanced_Stable_Analysis_v6.0"
                },
                "faces_data": faces_data,
                "output_files": generated_files
            }
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –¥–ª—è –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            analysis_file = f'examples/results/{base_name}_enhanced_biometric_analysis.json'
            debug_print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ {analysis_file}...", "DEBUG")
            with open(analysis_file, 'w', encoding='utf-8') as f:
                json.dump(image_result, f, indent=2, ensure_ascii=False, cls=NumpyEncoder)
            debug_print(f'‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {analysis_file}', "SUCCESS")
            
            all_analysis_results[base_name] = image_result
            
        except Exception as e:
            debug_print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {img_path}: {e}", "ERROR")
            import traceback
            traceback.print_exc()
            continue
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–≤–æ–¥–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –¥–ª—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    if len(all_analysis_results) > 1:
        debug_print('\nüìä –ì–ï–ù–ï–†–ê–¶–ò–Ø –°–í–û–î–ù–û–ì–û –û–¢–ß–ï–¢–ê', "INFO")
        
        try:
            # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –º–µ–∂–¥—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
            face_comparisons = compare_faces_embeddings(all_analysis_results)
            
            # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–≤–æ–¥–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞
            summary_report = {
                "analysis_summary": {
                    "total_images_processed": len(all_analysis_results),
                    "total_faces_detected": sum(
                        len(data["faces_data"]) for data in all_analysis_results.values()
                    ),
                    "processing_timestamp": str(np.datetime64('now')),
                    "version": "3DDFA_V2_Enhanced_Stable_Analysis_v6.0",
                    "improvements": [
                        "–°—Ç–∞–±–∏–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —Å –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏–µ–π –ø–æ–≤–æ—Ä–æ—Ç–æ–≤",
                        "–ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ 3D –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç —Å–æ–≥–ª–∞—Å–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏",
                        "–ò—Å–ø—Ä–∞–≤–ª–µ–Ω—ã –≤—Å–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏",
                        "–£–ª—É—á—à–µ–Ω–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –∏–∑–º–µ—Ä–µ–Ω–∏–π"
                    ]
                },
                "face_comparisons": face_comparisons,
                "detailed_results": all_analysis_results,
                "identity_analysis": analyze_identity_groups(face_comparisons),
                "statistical_summary": calculate_global_statistics(all_analysis_results)
            }
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–≤–æ–¥–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞
            summary_file = 'examples/results/enhanced_biometric_summary_v6.json'
            debug_print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–≤–æ–¥–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –≤ {summary_file}...", "DEBUG")
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary_report, f, indent=2, ensure_ascii=False, cls=NumpyEncoder)
            debug_print(f'‚úÖ –°–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {summary_file}', "SUCCESS")
            
            # –ü–µ—á–∞—Ç—å –∫–ª—é—á–µ–≤—ã—Ö –≤—ã–≤–æ–¥–æ–≤
            print_analysis_conclusions(summary_report)
            
        except Exception as e:
            debug_print(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–≤–æ–¥–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞: {e}", "ERROR")
            import traceback
            traceback.print_exc()
    
    debug_print('\nüéâ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù –£–°–ü–ï–®–ù–û', "SUCCESS")
    debug_print('‚úÖ –í—Å–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω—ã', "SUCCESS")
    debug_print('‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ —Å—Ç–∞–±–∏–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã', "SUCCESS")
    debug_print('‚úÖ –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ –ø—Ä–æ–¥–∞–∫—à–µ–Ω—É', "SUCCESS")



if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="–£–ª—É—á—à–µ–Ω–Ω—ã–π —Å—Ç–∞–±–∏–ª—å–Ω—ã–π –±–∏–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Å 3DDFA_V2")
    parser.add_argument("--config", type=str, required=True, help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
    parser.add_argument("--img_fp", type=str, required=True, help="–ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –∏–ª–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏")
    parser.add_argument("--onnx", action="store_true", help="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å ONNX –º–æ–¥–µ–ª—å")
    parser.add_argument("--mode", type=str, choices=["cpu", "gpu"], default="cpu", help="–†–µ–∂–∏–º CPU –∏–ª–∏ GPU")
    parser.add_argument("--opt", type=str, choices=["none", "all", "selected", "2d_sparse", "2d_dense", "3d", "depth", "pncc", "obj"],
                       default="all", help="–û–ø—Ü–∏–∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏")
    parser.add_argument("--selected_viz", type=str, nargs='+',
                       choices=["2d_sparse", "2d_dense", "3d", "depth", "pncc", "obj"],
                       help="–í—ã–±—Ä–∞–Ω–Ω—ã–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–ª—è --opt selected")
    parser.add_argument("--verbose", action="store_true", help="–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥ –æ—Ç–ª–∞–¥–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏")
    
    args = parser.parse_args()
    main(args)