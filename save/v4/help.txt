1. Архитектурные принципы и философия системы
1.1. Научная строгость и воспроизводимость
Система строится на принципах полной автоматизации, математической прозрачности и воспроизводимости. Каждый этап анализа — от извлечения 3D-геометрии до финального вердикта — реализуется через независимые модули, каждый из которых фиксирует свои действия в логах и сохраняет промежуточные результаты для последующего аудита. Это позволяет не только проводить независимую экспертизу, но и воспроизводить результаты на других выборках или с новыми версиями алгоритмов.

1.2. Модульность и масштабируемость
Архитектура разбита на 7 ключевых модулей, каждый из которых отвечает за строго определённую функцию:

utils.py — инфраструктура и сервисные функции

reference_manager.py — работа с эталонами и профилями

facial_feature_extractor.py — извлечение и нормализация 3D-геометрии

advanced_feature_analyzer.py — эмбеддинги и текстурный анализ

chronology_and_anomaly_detector.py — временные ряды, кластеризация, аномалии

main_processor.py — оркестрация анализа

gui_visualizer.py — экспертная визуализация и интерактивная аналитика

Каждый модуль может быть расширен или заменён без влияния на остальные компоненты, что обеспечивает гибкость и долгосрочную поддерживаемость системы.

2. Критические детали реализации по каждому модулю
2.1. utils.py — Инфраструктура и сервис
setup_logger:
Использовать стандарт logging с ротацией файлов, уровнем INFO и DEBUG, отдельными каналами для ошибок и событий. Логи должны содержать идентификатор сессии, имя модуля, временную метку и ключевые параметры вызова функций. Это важно для аудита и отладки цепочек анализа.

save_results_to_json:
Использовать сохранение с Unicode и форматированием. Для больших датасетов реализовать постраничное сохранение или хранение ссылок на внешние файлы с heavy-данными (например, массивы эмбеддингов).

get_age_from_date:
Корректно обрабатывать все возможные форматы дат, использовать стандарт datetime и учитывать високосные годы. Возраст возвращать с точностью до двух знаков после запятой.

load_config:
Все параметры (пороги shape error, параметры кластеризации, настройки нормализации) должны быть вынесены в YAML. Это позволит гибко настраивать систему без изменения кода и проводить A/B тесты различных гипотез.

2.2. reference_manager.py — Эталонные профили и маска Марквардта
get_marquardt_mask_references:
Эталонные значения должны быть рассчитаны заранее на основе анализа тысяч лиц, с учётом золотого сечения, анатомических исследований и публикаций по биометрии. Для каждого ракурса (frontal, frontal_edge, semi-profile, profile) должны быть отдельные наборы метрик:

Frontal: межзрачковое расстояние, ширина носа, ширина рта, высота лица

Profile: длина профиля, угол наклона лба, выступ носа, форма подбородка

Frontal edge и semi-profile: комбинации ключевых метрик с учётом перспективных искажений

get_subject_baseline_profile:
Профиль оригинального Путина должен быть построен на основе серии эталонных фото 1999-2001 годов, с расчётом средних значений и стандартных отклонений для каждой метрики по каждому ракурсу. Важно хранить не только средние значения, но и диапазоны допустимых отклонений, чтобы учитывать естественную вариативность.

2.3. facial_feature_extractor.py — 3D-геометрия и метрики
initialize_3ddfa_components:
Использовать конфиг mb1_120x120.yml или аналогичный, оптимизированный для портретных фото. Проверять наличие GPU и выбирать режим работы (gpu_mode) в зависимости от оборудования. FaceBoxes использовать для быстрой и точной детекции лиц на изображениях любой ориентации.

extract_3d_landmarks:
Для каждого изображения извлекать 68 ключевых 3D-ландмарков (или dense-версию — 38 000 точек при необходимости детального анализа поверхности). Корректировать оси X и Y согласно документации 3DDFA_V2 (Y инвертируется относительно высоты изображения). Для каждого ландмарка сохранять координаты X, Y, Z и confidence score.

determine_face_pose:
Использовать анализ Z-координат симметричных точек (глаз, носа, ушей) для определения ракурса. В случае пограничных случаев (например, между semi-profile и profile) использовать дополнительные критерии: угол между линией глаз и линией носа, степень видимости второго уха.

normalize_landmarks_by_pose:
Для каждого ракурса использовать уникальные пары опорных точек для нормализации:

Frontal: расстояние между внешними уголками глаз

Frontal edge: высота от бровей до подбородка

Semi-profile: расстояние от кончика носа до уха

Profile: длина профиля от лба до затылка
Все остальные расстояния и углы выражать в относительных единицах по этим базисам. Это полностью устраняет влияние масштаба, угла и технических шумов.

calculate_all_metrics:
Для каждого изображения рассчитывать полный набор метрик (300+):

Пропорции золотого сечения

Shape error (отклонение от средней формы)

Симметрия (коэффициенты по левой/правой половине)

Профильные и фронтальные углы

Орбитальный индекс, зигоматический угол, назолабиальный угол

Индексы выступа носа, подбородка, скул

Метрики глаз: ширина глазной щели, отношение радужки к белку, угол наклона

Параметры губ, носогубных складок, морщин

Индексы глубины (по Z-координатам)
Все метрики сохранять для последующего анализа и сравнения с эталоном.

calculate_shape_error:
Сравнивать извлечённую 3D-форму с эталонной моделью (например, BFM или усреднённой по базе реальных лиц). Shape error особенно важен для выявления масок и аномалий в области глаз, где даже минимальные отклонения указывают на неестественность.

2.4. advanced_feature_analyzer.py — Эмбеддинги и текстура
initialize_insightface_model:
Использовать предобученные модели InsightFace (например, Buffalo_L или ResNet-100), оптимизированные для портретных фото и лиц европейского типа. Проверять доступность GPU и выбирать оптимальный backend (CPU/GPU).

get_face_embedding:
Для каждого изображения извлекать 512-мерный эмбеддинг. Сохранять вектор эмбеддинга для последующего сравнения, кластеризации и анализа временных паттернов. Использовать косинусное расстояние между эмбеддингами для оценки степени сходства лиц.

analyze_skin_texture:
Использовать scikit-image для анализа текстуры по ключевым зонам (лоб, щеки, нос, область глаз):

LBP (Local Binary Pattern): для выявления микроструктуры кожи, пор, морщин

Энтропия Шеннона: для оценки однородности/разнообразия текстуры

Gabor-фильтры: для анализа направленных текстурных паттернов

Спектральный анализ (Fourier): для выявления регулярных паттернов, характерных для масок
Для каждой зоны сохранять гистограммы, средние значения, стандартные отклонения.

detect_mask_artifacts:
На основе текстурных метрик классифицировать уровень маскировки (5 уровней — от примитивных до нанотехнологий). Использовать пороговые значения энтропии, LBP, спектральных характеристик для автоматической маркировки подозрительных фото. В случае выявления аномалий — сохранять тип и зону их проявления.

2.5. chronology_and_anomaly_detector.py — Хронология, аномалии, хирургия
cluster_faces:
Использовать DBSCAN или иерархическую кластеризацию для группировки эмбеддингов. Критически важно выбирать параметры (eps, min_samples) на основе анализа распределения косинусных расстояний между эмбеддингами. Для каждого кластера сохранять временные интервалы появления, сопоставлять с историческими событиями.

build_aging_model:
Формировать модель старения на основе медицинских данных:

Гравитационные изменения (опущение тканей)

Потеря объёма (жировых пакетов)

Костная перестройка (углы, выступы)

Изменения текстуры кожи
Модель должна выдавать ожидаемые значения метрик для любого возраста, с доверительными интервалами.

check_surgical_intervention_hypothesis:
Анализировать временные интервалы между снимками с резкими изменениями метрик. Если интервал <6 месяцев и нет характерных послеоперационных паттернов (отеки, асимметрия, рубцы), хирургическая версия автоматически исключается. В случае подозрения на операцию — анализировать динамику изменений в течение 12-18 месяцев.

calculate_final_verdict:
Итоговый вердикт формируется по формуле:
Подлинность = 0.4 × Геометрия + 0.4 × Эмбеддинг + 0.2 × Текстура
Если итоговое значение <0.3 — фото классифицируется как маска, 0.3-0.7 — требуется дополнительный анализ, >0.7 — подлинное лицо. Для каждого фото сохраняется уровень доверия, тип аномалии и объяснение (feature importance).

2.6. main_processor.py — Оркестрация анализа
process_single_image:
Для каждого изображения поочерёдно вызываются:

initialize_3ddfa_components

extract_3d_landmarks

determine_face_pose

normalize_landmarks_by_pose

calculate_all_metrics

calculate_shape_error

initialize_insightface_model

get_face_embedding

analyze_skin_texture

detect_mask_artifacts
Все результаты агрегируются в единый словарь, который сохраняется для дальнейшей агрегации и анализа.

main:
Запускает полный цикл анализа директории:

Инициализация всех моделей

Обработка изображений в параллельном режиме (для ускорения)

Кластеризация эмбеддингов

Хронологический анализ, построение временных рядов

Финальный вердикт и сохранение результатов
Гарантируется корректная последовательность этапов, интеграция данных между модулями и полная трассировка всех действий.

2.7. gui_visualizer.py — Визуализация и экспертная аналитика
load_data:
Загружает результаты анализа из JSON, преобразует их в DataFrame для удобства фильтрации и визуализации.

Фильтрация и отображение:
Позволяет фильтровать фото по кластерам, ракурсам, датам, типам аномалий. Строит графики динамики ключевых метрик, отображает временные интервалы появления аномалий, сравнивает с эталоном и прогнозом старения.

Визуализация аномалий:
Строит карты аномалий по временным интервалам и ракурсам, отображает зоны проявления масок, резкие скачки метрик, динамику кластеризации. Позволяет эксперту быстро выявлять подозрительные периоды и проводить глубокий разбор каждого случая.

3. Ключевые алгоритмы и best practices
3.1. Работа с 3DDFA_V2
Использовать ортографическую проекцию для исключения перспективных искажений.

Корректировать оси X/Y согласно документации (Y инвертируется).

Для каждого ландмарка сохранять не только координаты, но и confidence score для фильтрации низкокачественных точек.

При работе с dense-ландмарками (38 000 точек) использовать downsampling для ускорения анализа без потери точности.

3.2. InsightFace
Использовать только последние версии моделей (Buffalo_L, ResNet-100), оптимизированные для портретных фото.

Для ускорения вычислений хранить эмбеддинги в бинарном формате (npz/hdf5).

Для кластеризации использовать косинусное расстояние; eps=0.35 — оптимальный порог для большинства задач.

Для анализа временных паттернов строить графики появления новых кластеров и сопоставлять их с историческими событиями.

3.3. scikit-image
Для LBP использовать радиус 3 пикселя и 24 направления, что оптимально для анализа кожи.

Энтропию считать по окнам 32x32 пикселя для выявления локальных аномалий.

Гистограммы LBP и спектральные характеристики хранить для каждой зоны лица отдельно.

Для выявления масок анализировать не только средние значения, но и распределение по зонам (лоб, щеки, нос, глаза).

4. Временные ряды и хронология
Для каждой метрики строить временные ряды с шагом в 1-3 дня (в зависимости от плотности датасета).

Анализировать динамику изменений: плавность, резкие скачки, периодичности.

Любые изменения, не объяснимые моделью старения или хирургией, автоматически маркируются как аномалии.

Для каждого кластера лиц строить отдельные графики появления/исчезновения, сопоставлять с историческими событиями (отсутствие на публике, госпитализации и т.д.).

5. Прозрачность, воспроизводимость, аудит
Все этапы анализа должны логироваться с детализацией до каждого вызова функции.

Все промежуточные результаты (метрики, эмбеддинги, текстурные характеристики) должны сохраняться для возможности независимой проверки.

Для каждого фото хранить полный набор исходных данных, метрик, результатов кластеризации, текстурного анализа и финального вердикта.

Визуализация должна позволять эксперту видеть не только финальный результат, но и весь путь анализа для каждого случая.

6. Расширяемость и дальнейшее развитие
Система должна позволять добавлять новые метрики, алгоритмы кластеризации, модели эмбеддингов без изменения существующего кода.

Возможна интеграция с другими биометрическими системами (например, анализ походки, голоса) для создания мультифакторной идентификации.

Возможна адаптация под анализ других персон, расширение базы эталонных профилей, обучение на новых данных.

7. Заключение
Детализированная архитектура и набор критических best practices, приведённые выше, обеспечивают не только максимальную точность и объективность анализа, но и прозрачность, воспроизводимость и долгосрочную поддерживаемость системы. Такой подход гарантирует, что любые аномалии, выявленные системой, будут иметь математически обоснованное и экспертно верифицируемое объяснение, что критически важно для задач судебной, исторической и научной экспертизы.