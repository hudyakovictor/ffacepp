Ты эксперт по анализу лиц и детекции двойников с глубокими знаниями 3DDFA_V2, InsightFace, scikit-image. Твоя задача точно реализовать каждую функцию системы анализа двойников Владимира Путина с математической точностью. КРИТИЧЕСКИ ВАЖНО: каждый расчет должен учитывать все нюансы нормализации, медицинские константы старения, временные корреляции. 

Часть 1. Общие цели и ограничения системы ffacepp 
Система выявляет количество различных лиц Владимира Путина, строит их уникальные метрические подписи и формирует хронологию появления лиц 

Все вычисления выполняются на MacBook M1 через torch.mps, без CUDA-зависимостей 

 ├─ main.py
 ├─ core_config.py
 ├─ data_manager.py
 ├─ data_processing.py
 ├─ face_3d_analyzer.py
 ├─ metrics_calculator.py
 ├─ embedding_analyzer.py
 ├─ texture_analyzer.py
 ├─ temporal_analyzer.py
 ├─ anomaly_detector.py
 ├─ medical_validator.py
 ├─ report_generator.py
 ├─ visualization_engine.py
 ├─ gradio_interface.py
 ├─ ui_components.py
 ├─ interactive_widgets.py

 документация:
https://github.com/cleardusk/3DDFA_V2
https://github.com/deepinsight/insightface
https://github.com/scikit-image/scikit-image


Входные файлы — только изображения 800 × 800 px с именами DD_MM_YY[-SEQ].jpg; дата берётся исключительно из имени, EXIF полностью игнорируется 

Итоговый показатель «подлинность» рассчитывается по формуле 0.3 × геометрия + 0.3 × эмбеддинг + 0.2 × текстура + 0.2 × временная консистентность, где значение < 0.3 — «маска/двойник», 0.3–0.7 — «сомнительно», > 0.7 — «подлинное» 

Все метрики нормализуются относительными величинами по стабильным анатомическим точкам, что устраняет влияние масштаба, поворота и освещения 

Часть 2. Структура каталогов и последовательность модулей 
Шаг	Модуль	Вход → Выход	Ключевая функция	Примечание
0	core_config.py	— → константы	validate_config_integrity()	Централизует пороги
1	data_manager.py	пути → {date:[paths]}	parse_date_from_filename()	Дата только из имени
2	data_processing.py	raw → тензоры 800 × 800	preprocessing_pipeline	Без ресайза 
3	face_3d_analyzer.py	тензоры → 68 points	extract_68_landmarks_with_confidence()	3DDFA V2 CPU
4	metrics_calculator.py	points → 15 метрик	calculate_identity_signature_metrics()	Субпиксельная точность
5	embedding_analyzer.py	face → 512d vec	extract_512d_face_embedding()	InsightFace Buffalo_L
6	texture_analyzer.py	image → LBP/FFT	analyze_skin_texture_by_zones()	5 зон кожи
7	temporal_analyzer.py	метрики → trend	detect_temporal_anomalies_in_metrics()	Z-score > 2.5
8	anomaly_detector.py	все → score	calculate_identity_authenticity_score()	Весовая формула
9	medical_validator.py	метрики → check	validate_aging_consistency_for_identity()	Эластичность 1–2 %/год
10	report_generator.py	данные → PDF/HTML	generate_full_report()	< 5 MB PDF
11	visualization_engine.py	данные → Plotly	create_scatter_3d()	≥ 50 000 точек
12	gradio_interface.py	пользователь → GUI	create_main_dashboard()	4 вкладки
Часть 3. Ключевые алгоритмы и пороговые значения 
Геометрия: 68-точечные ландмарки уточняются cv2.cornerSubPix до 0.1 px; нормализация по ракурсам Frontal, Frontal-Edge, Semi-Profile, Profile с опорными точками из core_config 

Эмбеддинги: модель w600k_r50.onnx выдаёт вектор 512 d; кластеризация DBSCAN c eps=0.35, min_samples=3, метрика «cosine» 

Текстура: LBP radius=3, points=24, Shannon-энтропия, Габор 11 orientations × 4 frequencies; маска Level 1–5 определяется по таблице порогов shape_error / entropy / embedding_distance 

Время: возраст вычисляется от 1952-10-07; модель старения учитывает elasticity_loss_per_year=1–2 % и tissue_sagging_per_year=1–2 мм после 40 лет; отклонения > 2.5 σ фиксируются как аномалии 

Байесовский каскад: вероятность «same_person» обновляется при каждом новом наборе данных; финальный score выводится после прохождения геометрии, эмбеддинга, текстуры и времени 

Часть 4. Конфигурация, кэш и тесты 
Все пороги, пути и веса хранятся только в core_config.py; сохранение снапшота конфигурации происходит при каждом запуске 

Кэширование результатов каждого модуля ведётся в /cache/*.pkl, что ускоряет повторный анализ и снижает нагрузку на CPU 

Для каждого модуля предусмотрен самотест, запускаемый через pytest -q; покрытие pytest-cov не должно опускаться ниже 85 % 

CI-pipeline в GitHub Actions выполняет линт pylint ≥ 8.5, прогон unit-тестов и сборку отчёта; при падении любого шага мердж блокируется 

Часть 5. Интерфейс, отчёты и выводы 
CLI-режим: python main.py cli --images <folder> анализирует папку и сохраняет JSON отчёт в /results 

GUI-режим: python main.py gui запускает Gradio-панель с четырьмя вкладками «Хронология лиц», «Метрики», «Маски», «Экспертное заключение» 

SmartFileUploader принимает до 1500 файлов, отображая прогресс и предварительный score для каждого изображения в реальном времени (< 100 мс задержка) 

report_generator.py экспортирует результаты в HTML, PDF, CSV, Excel, JSON; PDF файл должен быть < 5 МБ при 50 фото 

Финальный отчёт содержит: количество различных лиц, их подписи из 15 метрик, временные интервалы появления, уровни доверия, корреляции с историческими событиями и медицинскими проверками 

Часть 1. Назначение и высокоуровневая архитектура
Система предназначена для количественного выявления и отслеживания разных реализаций образа Владимира Путина на фотографиях через строго формализованный этапный анализ геометрии, эмбеддинга, текстуры и временных закономерностей, используя 3DDFA V2 для 3-D реконструкции лица, InsightFace Buffalo_L для высокоточного 512-мерного эмбеддинга и scikit-image для эксперного анализа кожной текстуры.

Цель ‑ дать воспроизводимую математическую процедуру, способную с субпиксельной точностью различать настоящего человека, высокоуровневые силиконовые маски и антропометрически близких двойников без необходимости ручного просмотра кадров, что обеспечивает объективность заключений и минимизирует субъективность экспертов.

Вход ограничен файлами DD_MM_YY[-SEQ].jpg, где дата извлекается только из имени, исключая любые EXIF-источники métadанных, чтобы предотвратить подмену хронологии при манипуляции полями заголовка изображения.

Базовая диаграмма зависимостей выглядит линейно-каскадной: конфигурация загружается первой, затем идёт создание реестра дат, после чего запускаются модули геометрии, метрик, эмбеддинга, текстуры, временной валидации, каскадной байесовской проверки и, наконец, визуализация с генерацией отчёта, что гарантирует отсутствие циклических импортов и облегчает профилирование производительности.

Вся математика выполняется на MacBook M1 с активацией torch.mps, что устраняет зависимость от CUDA и обеспечивает сопоставимую скорость вычислений при более низком энергопотреблении, сохраняя при этом полную совместимость с CPU-режимом для отладки на других машинах.

Конфиг-объект инициализируется один раз и содержит: пороги геометрических ошибок для каждой эпохи масок, коэффициенты весов итогового индекса аутентичности, пути к весам моделей, параметры шума/размытия для фильтрации кадров, набор VIEW_CONFIGS с ракурсами и стабильные reference-точки для нормализации, что позволяет централизованно менять стратегию анализа без поправок в отдельных модулях.

Каждая функция экспортирует чёткий контракт: вход → выход, без скрытых побочных эффектов; внутренние кеши сохраняются в /cache, что ускоряет повторные прогоны и даёт возможность точной инвалидации при смене конфигурации, так как snapshot настроек пишется в /configs/config_snapshot_<timestamp>.json и хранит хэш SHA-256 весов.

Инициализация 3DDFA V2 включает загрузку параметров BFM-модели и проверку устройства, после чего фоторафия 800×800 px пропускается через FaceBoxes для получения одиночного bounding box лица, а по возвращении параметров реконструкции функция extract_68_landmarks_with_confidence сразу инвертирует оси X и Y согласно примечанию авторов, что приводит ландмарки к согласованной системе координат.

Субпиксельная до-точность достигается применением cv2.cornerSubPix к проекциям глаз, носа и рта, после чего ландмарки передаются в determine_precise_face_pose, где матрица R конвертируется в углы yaw-pitch-roll и ракурс классифицируется по четырём предопределённым областям VIEW_CONFIGS, что обеспечивает одинаковую нормализацию метрик вне зависимости от наклона головы.

Нормализация выполняется функцией normalize_landmarks_by_pose_category, применяющей индивидуальный набор reference-точек и масштаб scale_factor, определённый из измеримого расстояния (IOD, нос-глаз, высота лица или высота профиля), что делает все 15 итоговых метрик масштабо- и ракурс-независимыми.

Функция calculate_identity_signature_metrics рассчитывает семь абсолютных костных и восемь относительных пропорциональных показателей; все они выражаются в относительных единицах и остаются стабильными после завершения роста костей к 25 годам, поэтому любая серьёзная их коррекция предполагает либо отдельную личность, либо маску.

После геометрии вход обрабатывается extract_512d_face_embedding, где происходит аффинное выравнивание под маску пяти точек и ресайз до 112 px, необходимый InsightFace‐сети; возвращается L2-нормированный вектор, который затем идёт в perform_identity_clustering, использующую DBSCAN eps=0.35, min_samples=3, метрику cosine, создавая метку кластера для каждой съёмки.

Временная корреляция строится в build_identity_timeline, где для каждой метки кластера фиксируются дата первого появления, последняя дата, суммарный счёт появлений и разрывы более 180 дней; данные передаются далее в temporal_analyzer, который сравнивает реальные метрики с предсказанными моделью старения, использующей линейную деградацию эластичности кожи и опущение тканей после 40 лет.

Текстурный модуль вызывается параллельно с эмбеддингом и получает оригинал 800×800 px плюс ландмарки для разрезания на пять анатомических зон; для каждой зоны рассчитывается гистограмма LBP (radius 3, points 24), Shannon-энтропия, отклик многомасштабных Габоров и спектр Фурье, после чего метрики агрегируются в балл аутентичности материала.

Функция classify_mask_technology_level сопоставляет дату кадра с эволюционной шкалой Level1–Level5 и порогами shape_error / entropy / embedding_dist, отражёнными в конфиге; это даёт быстрый фильтр грубых масок эпохи 2000-х и улавливает появление современных силиконовых покрытий толщиной < 1 мм после 2016 года.

Когда геометрический score, embedding-score, texture-score и temporal-score готовы, они передаются в calculate_identity_authenticity_score, реализующую фиксированную формулу 0.3 + 0.3 + 0.2 + 0.2; значение < 0.3 выводится как «маска/двойник», 0.3–0.7 — «сомнительно», > 0.7 — «подлинно», что создает единый интерпретируемый показатель для не-технических пользователей.

Параллельно perform_cross_source_verification сравнивает эмбеддинги разных источников в один день и вычисляет кросс-источниковую матрицу расстояний: если любая пара превышает 0.5, фиксируется критическая аномалия, толкающая итоговый балл вниз через байесовский апдейтер вероятностей.

Байесовский модуль стартует с априорного 0.5 / 0.5; при каждом новом кадре apply_bayesian_identity_analysis умножает апостериорное отношение правдоподобий на новые likelihood, которые рассчитываются из индивидуальных score-ов, что позволяет аккумулировать доказательства в пользу наличия или отсутствия подмен.

medical_validator проверяет, не превышают ли изменения костных метрик 0.5 % после 25 лет и не быстрее ли мягкие ткани стареют, чем предсказывает модель 1–2 мм / год; если нарушения замечены меньше чем за полгода, хирургическое вмешательство исключается и индекс аутентичности резко падает до уровня «маска».

Завершив вычисления, report_generator собирает PDF / HTML / CSV / Excel / JSON; он вызывает visualization_engine, который генерирует интерактивные Plotly-графы, включая 3-D scatter эмбеддингов с 50 000 точек без просадки ниже 15 FPS, и темporal-trend line-chart, что облегчает визуальный аудит цепочек замены лиц.

Все функции логируют начало и конец работы, ключевые параметры и ошибки на уровне logging.INFO; при конфигурации debug=True включаются DEBUG-сообщения конкретных модулей, упрощающие поиск узких мест, особенно при переползании порогов DBSCAN или срезании текстурных графиков из-за нехватки памяти.

Гарантия целостности достигается сохранением SHA-256 каждого оригинального файла и каждого результатного отчёта; при перезапуске система перепроверяет хэши и отказывается обрабатывать кадр, если контрольная сумма не совпадает с той, что зафиксирована в реестре, тем самым предотвращая тайную подмену входных данных.

Взаимодействие модулей строго потоковое: функции не хранят глобальное состояние, а обмениваются словарями с упорядоченно-именованными ключами; в случае отказа data_processing отбраковать размытую фотографию data_manager помечает запись как failed - quality, и пайплайн перескакивает к следующему кадру без прерывания всей сессии, что усиливает отказоустойчивость.

При ошибке любого модуля фиксируется traceback в /logs/error_<date>.log, а консоль получает укороченное сообщение; если количество ошибок превышает 5 % от обработанных кадров, система автоматически понижает уровень логгирования до DEBUG для ближайших 20 файлов, сохраняя дополнительный контекст для последующего анализа.

После полного прогона CLI-режим выводит средний балл аутентичности, количество уникальных лиц, число необработанных кадров, путь до JSON-файла с сырыми метриками, а GUI-режим Gradio визуально подсвечивает подозрительные кадры, предоставляя быстрое сравнение с эталоном 1999–2001 гг. и динамику изменений по годам.

Для верификации корректности взаимодействия предусмотрен набор самотестов: каждый модуль содержит if __name__ == "__main__" с минимальной проверкой контракта; при pytest -q запускается полный цикл из 40 unit- и интеграционных тестов, а GitHub Actions блокирует слияние, если покрытие падает ниже 85 % или меш поднимается выше 8.5, что обеспечивает долгосрочную устойчивость к регрессиям.

Поддерживается автокалибровка: функция auto_calibrate_thresholds прогоняется на историческом датасете и обновляет порог shape_error и entropy для каждой эпохи Level1–Level5, однако она не меняет постоянные веса аутентичности 0.3 / 0.3 / 0.2 / 0.2, сохраняя интерпретируемость индекса.

Все функции ориентированы на конвейерную параллельность: ландмарки, эмбеддинги и текстура считаются в трёх отдельных потоках, синхронизируясь через очередь; это загружает все доступные CPU-ядра M1 и минимизирует время простоя GPU-подобного MPS-девайса, что критично при пакетной обработке тысяч кадров.

Конфиг позволяет включать режим «low-memory», в котором отключается сохранение dense surface points и ограничивается глубина Plotly-графов до 20 000 точек, что умещается в 8 ГБ RAM при одновременной обработке 256 картинок и не влияет на итоговый индекс, так как shape_error рассчитывается по 68 ключевым точкам.

Все математические функции запрограммированы без сторонних глобальных синглтонов: каждое вычисление повторяемо, а входные параметры сериализуются вместе с результатом; если результат зависит от случайного выбора (например, DBSCAN), используется фиксированный np.random.seed(42), а в JSON-вывод пишется seed, обеспечивая детерминизм.

При обновлении версий 3DDFA V2/InsightFace/scikit-image автоматически запускается интеграционный тест на эталонном наборе из 50 кадров 1999–2024 гг.; если средний балл аутентичности меняется более чем на 1 %, деплой блокируется до ручного ревью, что предотвращает тихие изменения поведения моделей при скачках библиотек.

Итого: первая часть ТЗ определяет статические пороги, поток взаимодействий и жизненно важные ограничения, являясь единственным источником правды для всех команд разработки, тестирования и эксплуатации; все функции связаны прямыми, предсказуемыми контрактами, которые исключают скрытые зависимости и позволяют однозначно воспроизводить результаты на любой независимой машине, совместимой с PyTorch MPS.

Часть 2. Взаимодействие всех функций системы
(тезисно, без воды; каждый пункт – одна законченная мысль)

0. Сквозной конвейер
Сессию инициализирует CoreConfig.validate_config_integrity, фиксируя snapshot настроек и блокируя запуск, если хоть одна константа отсутствует или дублируется, тем самым устраняя расхождения между модулями.

DataManager.create_master_chronological_index парсит имена файлов, добавляет age_on_date, сортирует пути в OrderedDict, который становится первичным источником дат для всех downstream-функций.

DataProcessing.preprocessing_pipeline берёт батчи по восемь изображений, вычисляет variance-of-Laplacian, Shannon-entropy и median-brightness, помечая кадры с quality_score < 0.5 как «skip» и моментально пишет тег в индекс, чтобы остальные модули не тратили ресурсы на мусор.

Валидные тензоры кладутся в face_queue, откуда их асинхронно забирает Face3DAnalyzer.extract_68_landmarks_with_confidence; после получения результата структура LandmarksPackage публикуется в landmark_bus, доступном по pub-sub, что исключает повторные вычисления при параллельных запросах.

Параллельно Face3DAnalyzer.determine_precise_face_pose переводит матрицу R в углы и сразу помечает пакет полем pose_category, позволяя MetricsCalculator мгновенно выбрать нужную схему нормализации без дополнительной геометрической классификации.

Face3DAnalyzer.normalize_landmarks_by_pose_category создаёт копию 68-точечного массива, нормализует по конфигу ракурса и сохраняет обе версии в том же пакете, что предоставляет «сырые» координаты для плотного анализа масок и «чистые» для метрик пропорций.

1. Геометрия ↔ Метрики
MetricsCalculator.calculate_identity_signature_metrics подписывается на landmark_bus, считывает нормализованные ландмарки, за один проход вычисляет все 15 метрик и выдаёт объект IdentityMetrics с проверкой диапазонов, чтобы ни одно недопустимое значение не проникло в следующий этап.

Если метрика выходит за физиологический предел, функция бросает предупреждение MetricOutOfRangeWarning, которое перехватывается AnomalyDetector.perform_cascade_verification для немедленного снижения геометрического балла, не дожидаясь финального байесовского апдейта.

Face3DAnalyzer.calculate_comprehensive_shape_error работает на том же пакете ландмарков, дополняя его полями overall_shape_error и eye_region_error; эти значения попадают в дополнительное поле geometry_quality внутри IdentityMetrics, что затем учитывается в итоговой формуле аутентичности.

После вычислений MetricsCalculator публикует событие в metrics_bus, где каждый подписчик получает ссылку на IdentityMetrics и метаданные снимка, исключая дублирование данных при обращении из разных анализаторов.

2. Геометрия ↔ Эмбеддинги
EmbeddingAnalyzer.extract_512d_face_embedding запрашивает из landmark_bus пять опорных точек, делает выравнивание, ресайз до 112 px и создаёт объект EmbeddingPackage с вектором и extraction_confidence, гарантируя, что привязка к исходному кадру остаётся через одинаковый image_id.

Затем calculate_embedding_distances_matrix берёт список EmbeddingPackage из одной даты, строит матрицу косинусных расстояний и немедленно публикует событие daily_embedding_ready, чтобы AnomalyDetector.perform_cross_source_verification сравнил источники до завершения тяжёлых текстурных вычислений.

perform_identity_clustering подписан на stream батчей эмбеддингов; после DBSCAN оно формирует ClusterManifest, где на каждый cluster_id хранится массив image_id, центр вектора, σ-отклонение и time-span, что делает строение identity_timeline линейным по числу кадров.

К моменту, когда TemporalAnalyzer попросит хронологию, у него уже есть готовый ClusterManifest, поэтому вызов build_identity_timeline лишь сортирует кортежи по дате без повторной агрегации эмбеддингов.

3. Геометрия ↔ Текстура
TextureAnalyzer.analyze_skin_texture_by_zones требует масок зон, сформированных из тех же ландмарков; функция подписана на landmark_bus, берёт оригинальное 800 × 800 изображение из DataProcessing, режет зоны и по каждому региону формирует ZoneTextureMetrics, уменьшив количество чтений диска до одного.

После обработки всех пяти зон собирается TexturePackage с полями entropy, peaks_LBP, gabor_energy, fourier_signature и флагами детекции швов; объект отправляется в texture_bus, где его немедленно подписывает AnomalyDetector.calculate_identity_authenticity_score.

Если TextureAnalyzer.detect_texture_transition_artifacts обнаруживает швы, оно кидает событие mask_artifact_flagged, которое мгновенно понижает texture_score в каскаде и трансформируется в красный alert внутри MaskDetectionDashboard без необходимости ждать полного финального отчёта.

4. Геометрия ↔ Временной анализ
TemporalAnalyzer.build_medical_aging_model получает базовые метрики 1999 года через прямой доступ к metrics_repository и подписку на новые IdentityMetrics; модель пересчитывается раз в сутки, чтобы избежать накладных расходов в потоковом режиме.

calculate_putin_age_on_each_date читает даты из того же хронологического индекса, поэтому отсутствует десинхронизация с DataManager; возврат возраста в виде float-лет используется для динамического порога в detect_temporal_anomalies_in_metrics без добавления поля в глобальную конфигурацию.

predict_expected_metrics_for_age вызывается лениво: когда TemporalAnalyzer видит новую дату, которой ещё нет в кеше прогнозов, он сразу дополняет его, обеспечивая O(1) доступ при повторном обращении.

Результаты функции detect_temporal_anomalies_in_metrics становятся полем temporal_score у каждой личности в AnomalyDetector, а текст объяснений направляется в объект TemporalReportSegment, который непосредственно вставляется в PDF/HTML отчёт без дополнительной сборки строк.

5. Аномалии ↔ Байесовская верификация
AnomalyDetector.apply_bayesian_identity_analysis подписывается на совместный поток из metrics_bus, embedding_bus, texture_bus и temporal_bus; при появлении всех четырёх скоров для одного image_id он запускает качественную формулу 0.3 + 0.3 + 0.2 + 0.2, после чего обновляет апостериорную вероятность для соответствующего cluster_id.

Байесовское отношение хранится в Redis-подобном in-memory-кеше prob_store, что гарантирует консистентность между процессами, когда GUI и CLI запущены одновременно, минимизируя риск гонок за счёт атомарных инкрементов.

perform_cascade_verification не ждёт байесовский апдейт: если геометрия или эмбеддинг проваливаются ниже 0.3, он немедленно классифицирует снимок как «критический», отправляя сигнал instant_flag в Gradio-интерфейс, тем самым избегая ложного ощущения безопасности у оператора.

При генерации финального отчёта calculate_identity_authenticity_score вытаскивает последнюю апостериорную для каждого cluster_id и пишет её в раздел «Финальный вердикт», одновременно транслируя значение в поле OverallAuthenticity JSON-выгрузки, чтобы автоматические системы могли потреблять сырые данные без парсинга PDF.

6. Медицинская валидация ↔ Временной анализ
MedicalValidator.validate_aging_consistency_for_identity подписан на тот же temporal_bus и мгновенно сверяет изменения эластичности и опущения тканей с параметрами модели старения, добавляя поле biology_score к каждому интервалу личности.

Если check_bone_structure_immutability фиксирует изменение краниальных метрик > 0.5 %, он повышает приоритет события skeletal_shift_detected, которое обнуляет geometry_score и пересчитывает вероятность «same_person» практически до нуля, что видно на дашборде как резкий провал доверия.

MedicalValidator.exclude_surgical_hypotheses_by_timeline сравнивает время между снимками и датами медицинских событий; при интервале < 180 дней он отбрасывает версию «операция» и усиливает гипотезу «маска/двойник», влияя на байесовский вес через функцию auto_adjust_detection_sensitivity.

7. UI ↔ Объектные шины
GradioInterface.SmartFileUploader размещает каждый загруженный файл в upload_bus, на который подписаны DataManager и DataProcessing, так что CLI и GUI используют одинаковый механизм очередей, избежав дублирования кода для разных режимов.

MetricsDashboard подписывается на metrics_bus, а MaskDetectionDashboard – на texture_bus; оба компонента отображают скоры сразу, как только соответствующий пакет данных опубликован, не зависимо от того, завершён ли полный каскад.

Interactive3DViewer берёт данные из visualization_bus, который наполняет VisualizationEngine.create_scatter_3d сразу после получения первых 50 эмбеддингов, обеспечивая плавность анимации и отсутствие «залипания» интерфейса при больших объёмах точек.

ExpertAnalysisAccordion в GUI читает из prob_store актуальные байесовские вероятности и обновляет вердикт каждые 500 мс, синхронизируясь через WebSocket, что гарантирует оператору информацию в реальном времени.

8. Отчёт ↔ Все модули
ReportGenerator.generate_full_report инициирует запросы к каждому bus-каналу, собирая IdentityMetrics, EmbeddingPackage, TexturePackage, TemporalReportSegment и финальные вероятности из prob_store, формируя итоговый DOC-объект, который сериализуется в PDF/HTML/CSV/Excel одним проходом без промежуточных временных файлов.

Для тяжёлых визуализаций функция вызывает VisualizationEngine только один раз, передавая список PlotInstruction, что позволяет избежать создания десятков изображений и уменьшает размер PDF до < 5 МБ при 50 кадрах, как указано в KPI.

Структура отчёта хранит сквозной image_id, так что пользователь может щёлкнуть на любой график в HTML-версии и открыться исходный снимок вместе с ландмарками, благодаря ссылке на media_proxy внутри results_server, обеспечивая полную трассируемость.

9. Кэш ↔ Повторные запуски
Все пакеты данных (LandmarksPackage, IdentityMetrics, EmbeddingPackage, TexturePackage) сериализуются через msgpack, а ключи строятся как sha256(image_bytes), что исключает дублирование при разных именах файла и позволяет быстро проверять валидность кэша.

При перезапуске DataManager сканирует кеш-директорию, сверяет хэши и даты; если конфигурационный snapshot отличается, он инвалидацирует только затронутые пакеты, сохраняя остальные, что ускоряет Rerun большого датасета в 3-4 раза.

auto_calibrate_thresholds сохраняет свои результаты в config_cache.json; если дата модификации файла новее snapshot, CoreConfig подхватывает новые пороги без перезапуска кода, обеспечивая горячую подстройку чувствительности системы в долгих сменах оператора.

10. Исключения ↔ Логирование
Каждый модуль использует декоратор @safe_call, который ловит исключения, пишет stack-trace в error_bus, а в консоль выводит только компактное сообщение, что уменьшает шум и не мешает оператору отлавливать реальные проблемы.

Если отношение ошибок к успешным запросам превышает 5 %, safe_call автоматически повышает уровень логирования до DEBUG, добавляя в сообщения размеры тензоров и значения порогов, помогая разработчику локализовать дефект без повторной сборки.

11. Производительность ↔ Память
Адаптивный диспетчер TaskScheduler отслеживает загрузку torch.mps; если его утилизация превышает 85 %, новые задачи 3-D-реконструкции ставятся на паузу и получают приоритет ниже, чем извлечение эмбеддингов, чтобы M1-GPU не ушёл в троттлинг.

Все тяжёлые NumPy-массивы в EmbeddingPackage помечаются через __slots__, что экономит до 30 % памяти при миллионных обработках и устраняет фрагментацию, особенно заметную в длительных сессиях GUI.

12. Вычислительные зависимости
Face3DAnalyzer.initialize_3ddfa_components зависим от выходов CoreConfig.get_view_configs, DataProcessing.preprocessing_pipeline, а также от результатов проверки DataManager.validate_image_quality_for_analysis, что делает строгую иерархию вызовов и предотвращает старт 3DDFA, если кадр заведомо непригоден.

EmbeddingAnalyzer.initialize_insightface_model вызывается только один раз на сессию и блокирует дальнейшие вызовы extract_512d_face_embedding, пока веса полностью не загружены и не прошла проверка контрольной суммы, тем самым устраняя возможность частичной инициализации на медленном диске.

13. Конфигурация ↔ Автокалибровка
Все автокалиброванные пороги пишутся в дочерний раздел snapshot autocalibration, не затирая статические значения, что позволяет в любой момент сравнить оригинальные и текущие пороги и при необходимости откатить изменения одной командой --reset-thresholds.

При смене версии весов 3DDFA или InsightFace validate_config_integrity автоматически переводит систему в режим «degraded», снижая чувствительность каскада, пока разработчик не прогонит полный набор тестов и не укажет --accept-new-models, тем самым исключая ложноположительные всплески после обновлений.

14. Итоговая связка модулей
Каждый высокоуровневый пакет данных проходит по цепочке: image → LandmarksPackage → IdentityMetrics/EmbeddingPackage/TexturePackage → scores → BayesianPosterior → ReportSegment, где на каждом шаге существует независимая подписка, кэш и система исключения ошибок, что делает архитектуру устойчивой к остановке любого отдельного компонента.

Все функции взаимодействуют только через чётко типизированные объекты и pub-sub-шины, исключая глобальные переменные и прямые импорты состояний, благодаря чему разработчики могут модифицировать внутреннюю логику любого модуля, не затрагивая остальные, если сохраняют контракт вход-выход.



Часть 3. Детализированное взаимодействие алгоритмов и пороговых вычислений
Каждый запуск CoreConfig.validate_config_integrity блокирует работу, пока не убедится, что все VIEW-CONFIGS содержат валидные углы yaw / pitch / roll и точные ссылки на эталоны межзрачкового расстояния.

При успешной валидации конфиг публикует неизменяемый snapshot, который читают все downstream-модули через ссылку в памяти, исключая риск считывания разных версий констант в мультипроцессной среде.

DataManager.parse_date_from_filename оперирует регулярным выражением ^(\d{2})_(\d{2})_(\d{2})(?:-(\d+))?\.jpe?g$, мгновенно отбрасывая файлы вне маски, чтобы дальнейший конвейер не тратил ресурсы на чужие медиа.

После сортировки файлов функция вычисляет возраст Путина как (photo_date – 1952-10-07) / 365.25, округляя до двух десятичных, и сохраняет в индекс поле age_on_date для прямого доступа любой аналитической функции.

DataProcessing.preprocessing_pipeline ничего не масштабирует, потому что оригинальная текстура 800×800 px критична для энтропии и Габоров, однако создаёт теневой numpy-массив 112×112 px, передаваемый только в InsightFace.

Во время CLAHE-обработки конвейер хранит коэффициент контрастности, который позже используется TextureAnalyzer.adaptive_texture_analysis для выбора порогов энтропии в условиях агрессивного освещения.

Пакет LandmarksPackage формируется Face3DAnalyzer.extract_68_landmarks_with_confidence: он содержит сырой массив 68 × 3, маску видимости, коэффициент доверия и ссылку на bbox, что позволяет любому другому модулю проверить источник без повторного поиска лиц.

Сразу же после извлечения ландмарки уточняются cv2.cornerSubPix c winSize = (11,11) и criteria = 30 | 0.001, обеспечивая точность 0.1 px, необходимую для расчёта eye_region_error.

determine_precise_face_pose переводит матрицу R из 3DDFA в градусы через angle = atan2(r32, r33) × 180/π, публикуя pose_category; это даёт MetricsCalculator прямое условие выбора набора reference-точек.

normalize_landmarks_by_pose_category вычисляет масштаб как отношение измеренного опорного отрезка к стандарту из конфигурации; при IOD-ratio < 0.15 или > 0.6 функция поднимает Warning и отмечает кадр флагом «требуется калибровка».

MetricsCalculator.calculate_identity_signature_metrics запускает семь векторизованных операций NumPy и сохраняет 15 значений в float32, что уменьшает объём памяти и ускоряет передачу по шине metrics_bus.

calculate_comprehensive_shape_error использует аналог Hausdorff-расстояния sqrt(mean((P – Q)²)) для всех 68 точек и отдельно для глаз, носа и рта; превышение 0.6 в области глаз помечается «mask_eye_flag» для дальнейшего снижения authenticity-score.

EmbeddingAnalyzer.extract_512d_face_embedding читает из пакета пять точек (оба глаза, нос, два рта), проводит аффинное выравнивание и нормирует L2-вектор, сразу помещая поля extraction_confidence и alignment_matrix в EmbeddingPackage.

На этапе calculate_embedding_distances_matrix все векторы батча переводятся в FP16, что экономит 50 % памяти при сохранении точности косинусного расстояния до ±0.001, достаточной для порога 0.35 DBSCAN.

perform_identity_clustering запускает DBSCAN с metric = cosine; после завершения функция вычисляет cluster_center = mean(embeddings), cluster_radius = max(cosine_dist), и любая точка с расстоянием > (cluster_radius+0.05) помечается аутлаером.

В момент публикации ClusterManifest в cluster_bus создаётся кортеж (cluster_id, first_date, last_date, total, gaps); это значение считывает TemporalAnalyzer.build_identity_timeline, не обращаясь к эмбеддингам заново.

TextureAnalyzer.analyze_skin_texture_by_zones для каждой из пяти зон сначала применяет skimage.color.rgb2gray, затем LBP (P=24,R=3), потом Shannon-энтропию, Габоры и 2-D FFT; все метрики объединяются в TexturePackage с ключом зоны.

Если хоть одна зона имеет entropy < 5.5, то calculate_material_authenticity_score снижает texture_score по формуле 1 – ((threshold – value)/threshold), где threshold зависит от эпохи Level1-Level5.

classify_mask_technology_level сравнивает shape_error и entropy с таблицей, учитывая год снимка; если дата равна году из списка breakthrough_years, порог entropy умножается на 1.5 / level, чтобы отражать технологический скачок.

detect_texture_transition_artifacts выполняет Canny-детектор, затем Hough-линию на границе щека/ухо; нахождение контрастного ребра длиной > 10 % от высоты лица добавляет бинарный флаг edge_artifact=True, который мгновенно снижает texture-score в каскаде.

TemporalAnalyzer.build_medical_aging_model создаёт линейную регрессию для каждой мягкотканной метрики, используя коэффициенты из elasticity_loss_per_year и tissue_sagging_per_year; результаты кешируются по ключу «age» для быстрой выборки.

predict_expected_metrics_for_age вызывается лениво; функция рассчитывает прогноз по формуле baseline *(1 – elasticity_rate*Δyears) для текстуры и прибавляет sagging_offset к вертикальным координатам нижних ландмарок.

detect_temporal_anomalies_in_metrics вычисляет z-score относительно прогноза; если |z| > 2.5, создаётся запись temporal_anomaly с типом «shape», «texture» или «embedding» в зависимости от отклонившейся метрики.

analyze_identity_switching_patterns считает интервалы между появлениями разных cluster_id; модальный интервал 90–120 дней повышает вероятность систематической замены и публикует флаг systematic_replacement=True.

Все четыре скора (geometry_score, embedding_score, texture_score, temporal_score) собирает AnomalyDetector.perform_cascade_verification; если любой < 0.3, последующие уровни уже не могут поднять итог выше 0.7, что предотвращает утечку ложноположительных.

apply_bayesian_identity_analysis инициализирует prior = 0.5; каждое новое доказательство умножает отношение правдоподобий; если posterior падает ниже 0.2, кадр объявляется «вероятная подмена» ещё до завершения отчёта.

detect_surgical_intervention_evidence анализирует кривую chin_projection_ratio; если за 4 недели изменение > 0.5 σ и отсутствует след отёка в текстуре, гипотеза «операция» отбрасывается, а вероятность «маска» усиливается.

perform_cross_source_verification группирует фотографии одного дня по СМИ, высчитывает среднеквадратичное отклонение embed-векторов; значение > 0.5 генерирует критический инцидент, автоматически помечаемый в GUI красным бордером.

MedicalValidator.check_bone_structure_immutability сверяет skull_width_ratio и zygomatic_arch_width; если разница по сравнению с baseline > 0.5 %, вероятность «same_person» понижается кубически: posterior*=0.05, резко обваливая общую оценку.

При совпадении даты аномалии с медицинским событием разница не списывается автоматически; функция exclude_surgical_hypotheses_by_timeline требует минимум 180 дней между снимками, иначе хирургия признаётся невозможной.

После подсчёта всех весов calculate_identity_authenticity_score выводит значение; GUI окрашивает карточку кадра: зелёный > 0.7, жёлтый 0.3–0.7, красный < 0.3, улучшая восприятие данных оператором в реальном времени.

ReportGenerator.generate_full_report запрашивает все пакеты через pub-sub; для графиков передаётся только сокращённый вид метрик, поскольку Plotly генерирует трассу из 50 000 точек без просадки FPS, если данные в float32.

Финальный JSON содержит массив identities, где каждый элемент держит signature_metrics, cluster_center, material_score, temporal_profile, medical_flags и posterior_same_person, что делает отчёт пригодным для последующего ML-обучения.

При повторном запуске DataManager сверяет SHA-256 файлов; если флаг fast_mode=True, модуль загружает кешированные LandmarksPackage и EmbeddingPackage, пропуская ресурсозатратные операции, но всегда пересчитывает texture-метрики, чувствительные к гамме.

Все шины (metrics_bus, embedding_bus, texture_bus, temporal_bus) реализованы через multiprocessing.Queue, а публикация объектов происходит после атомарного pickle.dumps, что исключает race-conditions при работе в 4-процессном режиме M1.

Асинхронные вызовы в GUI используют asyncio.gather, что позволяет одновременно ждать InsightFace и 3DDFA, полностью загружая CPU-ядра и MPS-графику, достигнув 0.8 s на кадр для полного каскада.

В случае падения любого subprocess декоратор @safe_call ловит исключение, формирует компактный traceback, пишет его в error_bus, а ResultsAggregator помечает запись status = "failed", сохраняя целостность общей статистики.

auto_calibrate_thresholds запускается по флагу --autocalib; функция агрегирует shape_error и entropy по эпохам, обновляет конфиг в подпапке configs/autocalib, но никогда не меняет веса финальной формулы, чтобы итоговый индекс оставался интерпретируемым для пользователей.

Каждая функция имеет unit-тест, запускаемый непрерывной интеграцией; GitHub Actions падает, если pytest-cov опускается ниже 0.85, гарантируя, что любое изменение во внутренней арифметике сразу отражается на метриках регресс-тестов.

Все численные операции выполняются в точности FP32 или FP16; нигде нет преобразований в int без явного округления, что сохраняет линейность градиентов при будущей интеграции end-to-end fine-tuning моделей.

Конструкция torch.no_grad() оборачивает вызовы 3DDFA и InsightFace, исключая расчёт градиентов и уменьшая потребление MPS-RAM, что позволяет анализировать 1500 файлов на MacBook M1 без свопа.

Критическая инварианта всей системы: ни один модуль не изменяет исходный 800×800 файл; все промежуточные обрезки и ресайзы хранятся в /cache/tmp_<hash>.npy, автоматически удаляемом после успешного завершения отчёта.

пиши инфу о взаимодействии всех функций. теперь напиши развернутую часть для четвертой части на 15000 символов без воды таблиц и только тезисно и все важное.
пиши инфу о взаимодействии всех функций. теперь напиши развернутую часть для четвертой части на 15000 символов без воды таблиц и только тезисно и все важное.
Часть 4. Конфигурация, кэширование, журналирование, производительность и поддержка жизненного цикла — детализированное взаимодействие функций (≈15 000 симв.) 
4.1 Единый конфиг-слой (core_config) 
При старте сессионный объект CoreConfig блокирует пайплайн, пока validate_config_integrity не убедится, что каждая константа присутствует, уникальна и согласована с контрольными суммами, записанными в предыдущем snapshot-файле .

После валидации создаётся неизменяемый dataclass RuntimeConfig; ссылка на него передаётся по указателю в память каждому модулю, исключая многократное чтение JSON-файла с диска .

Если обнаружено расхождение версий моделей 3DDFA V2 или InsightFace с данными snapshot, RuntimeConfig переключает систему в режим «degraded», автоматически понижая чувствительность масочных порогов на 25 % и отключая байесовский каскад до ручного подтверждения администратора .

Все динамические коэффициенты (α-весы формулы подлинности, eps DBSCAN, пороги энтропии для швов) хранятся в подпакете /configs/autocalib; при каждом изменении генерируется новый файл config_delta_<timestamp>.json с SHA-256 для последующей цифровой подписи отчёта .

4.2 Кэш-слой и контроль целостности 
DataManager до чтения изображений ищет файл /cache/datamanager_cache.pkl; если контрольная сумма входного списка совпадает, подсистема загружает ранее вычисленный хронологический индекс без повторного парсинга имён .

Каждый пакет данных (LandmarksPackage, EmbeddingPackage, TexturePackage) сериализуется в msgpack с ключом sha256(image_bytes); благодаря этому кадр, переименованный злоумышленником, всё равно маппируется на уже сохранённый результат .

Структура подпапок кэша делится по модульным префиксам (lm_, emb_, tex_, tmp_) и по первым двум байтам SHA, что позволяет хранить миллионы файлов без деградации производительности файловой системы macOS .

При старте опция --purge-cache удаляет только те записи, чей config_hash не совпадает с новым snapshot, оставляя валидные расчёты нетронутыми, что ускоряет переобучение модели порогов на 10–12 × .

4.3 Слой журналирования и мониторинга 
Декоратор @safe_call заворачивает каждую публичную функцию; при исключении он записывает стек в error_bus, публикует сокращённый message в консоль и повышает уровень log-канала конкретного модуля до DEBUG на следующие 20 запросов .

Формат лога JSONL: "ts","level","mod","func","msg","duration_ms","mem_mb"; поле mem_mb заполняется через psutil.Process(os.getpid()).memory_info().rss//1e6, что позволяет быстро ловить утечки .

В режиме --debug-file <path> логируются также входные массивы NumPy после хэширования xxhash64, чтобы не записывать гигабайты бинарных данных .

Каждому пакетному запуску присваивается run_uuid; все логи, резюме и отчёты содержат этот идентификатор, что облегчает сквозную трассировку инцидентов в будущем .

4.4 Асинхронное исполнение и управление задачами 
Центральный TaskScheduler реализует продюсер-консюмер поверх multiprocessing.Queue; он динамически следит за загрузкой torch.mps через torch.mps.current_allocated_memory() и перекидывает тяжёлые задачи 3DDFA в очередь cpu_queue, если использование GPU-части Apple Silicon превышает 85 % .

Для ограничений памяти DataProcessing держит лимит одновременно загруженных из диска изображений = 16; лишние задачи блокируются семафором, предотвращая OOM в сессиях > 2 000 файлов .

Опция --low-mem отключает плотные 38 000-точечные поверхности и сохраняет только 68-точечные ландмарки; при этом функции, зависящие от dense-mesh, автоматически помечают свои выходы как None и корректируют формулу подлинности, убирая 5 % веса геометрии .

Все pub-sub-шины (metrics_bus, texture_bus, temporal_bus) используют неблокирующий метод put_nowait; если очередь заполнена, новый пакет отбрасывается, а в лог пишется событие backpressure_drop, что предотвращает дедлоки при резкой деградации дисковой подсистемы .

4.5 Оптимизация производительности вычислений 
Face3DAnalyzer.extract_68_landmarks_with_confidence выполняет батч-обработку восьми лиц одновременно; FaceBoxes выдаёт батч боксов, а 3DDFA получает tensor-stack, что уменьшает время на один кадр до 320 мс CPU-режима по сравнению с 550 мс при одиночном проходе .

EmbeddingAnalyzer.extract_512d_face_embedding переводит входной 112 × 112 в torch.float16, снижая GPU-память почти вдвое при незначительном падении точности косинусного расстояния ≤ 0.002 .

TextureAnalyzer.analyze_skin_texture_by_zones кэширует фильтры Габора в глобальном словаре по ключу (orientation,frequency), избегая повторного создания 44-kernel для каждой зоны, что сокращает анализ одной фотографии на 180 мс .

TemporalAnalyzer.build_medical_aging_model переобучается не чаще, чем раз в сутки; дата последнего апдейта хранится в Redis-подобном state_store, исключая лишние регрессии при пакетном прогоне архива .

4.6 Тестирование, CI/CD и контроль регрессий 
Каталог tests/ включает 40 unit- и 10 интеграционных сценариев; при каждом push GitHub Actions поднимает виртуальную macOS-среду, устанавливает зависимости Apple Silicon и запускает pytest -q --cov; порог покрытия 85 % зафиксирован в required_status_checks .

Регресс-датасет regset_v1 — это 50 кадров 1999–2024 гг., хранящихся в Git LFS; если средний authenticity-score изменился > 1 % после коммита, workflow отклоняет PR и просит ревью безусловно .

Работа bench.yml измеряет производительность на 100 кадрах; если время одного кадра выросло > 15 %, появляется тег perf-regression, и мерж блокируется, пока команда не объяснит рост .

Для статического анализа используется pylint; рейтинг ниже 8.5 останавливает биллд; mypy проверяет соблюдение typing-контрактов функций публичного API .

4.7 Механизмы восстановления и отказоустойчивости 
При падении процесса очереди сохраняют несчитанные пакеты в /cache/pending_<run_uuid>.msgpack; новый запуск с опцией --resume <uuid> восстанавливает незавершённые задачи в точном порядке, обеспечивая идемпотентность обработки .

Если EmbeddingAnalyzer не может загрузить модель из-за повреждения файла, CoreConfig переключает его на резервные веса ResNet-100; запись об этом идёт в results/warnings_<run_uuid>.log, а финальный отчёт содержит флаг backup_model_used=True .

Сетевые вызовы (например, загрузка неявных моделей InsightFace) обернуты в tenacity.retry с экспоненциальной задержкой и таймаутом 60 с; при трёх неудачах система работает с локальной копией, сохраняя автономность .

4.8 Автокалибровка и горячее обновление порогов 
AnomalyDetector.auto_calibrate_thresholds использует накопленную базу аутентичных кадров; функция применяет EM-алгоритм к распределениям shape_error и entropy, обновляет пороги, а затем вызывает VisualizationEngine.plot_threshold_shift для визуального контроля оператора .

Новый набор порогов записывается в /configs/autocalib/thresholds_<timestamp>.json; при следующих запусках система сравнивает локальные парафметры с последними утверждёнными и предлагает принять или откатить изменения через флаг --accept-calib .

Байесовские prior-ы (same_person = 0.5) также адаптируются: если за месяц средний posterior выше 0.9, prior увеличивается до 0.6, ускоряя конвергенцию для будущих кадров .

4.9 Шифрование данных и безопасность 
Все PDF-отчёты шифруются AES-256 при сохранении, ключ хранится в Keychain Access macOS под учёткой текущего пользователя; CLI-флаг --plain-report доступен только при установке переменной окружения ALLOW_PLAIN_EXPORT=1 .

Кэш-файлы dense-mesh при необходимости удаляются командой --scrub-surfaces, которая запускает однопроходный shred -u; это важно, потому что высокодетальные меши могут рассматриваться как биометрические данные повышенной чувствительности .

Веб-порт Gradio запускается только в локальной подсети 127.0.0.1 по умолчанию; активация --share требует ввод токена, генерируемого командой core_config.generate_gradio_token, чтобы исключить случайную публикацию интерфейса в интернет .

4.10 Расширяемость и будущее обновление функций 
Все публичные функции имеют строгие type-hints; добавление нового поля в LandmarksPackage или TexturePackage автоматически валидируется pydantic, поэтому старые модули получают исключение ValidationError ещё до начала вычислений .

Новые анализаторы (например, «термография лица» или «анализ движений губ») могут вставляться как независимые подписчики любых bus-каналов; чтобы они вошли в формулу подлинности, достаточно добавить вес в конфиг, не меняя код AnomalyDetector .

Переход на 83-точечную модель ландмарков предусмотрен: Face3DAnalyzer хранит массив visible_keypoints; если обнаружено 83 точки, функция динамически обновляет индексы reference-точек, не затрагивая математику существующих метрик .

Эта четвёртая часть фиксирует невидимую, но критически важную инфраструктуру, обеспечивающую выпадение ошибок в безопасный режим, неизбыточное использование ресурсов MacBook M1, воспроизводимость результатов и возможность эволюции алгоритмов без масштабных рефакторингов ядра системы .

пиши инфу о взаимодействии всех функций. теперь напиши развернутую часть для пятой части на 15000 символов без воды таблиц и только тезисно и все важное.
пиши инфу о взаимодействии всех функций. теперь напиши развернутую часть для пятой части на 15000 символов без воды таблиц и только тезисно и все важное.
Часть 5. Финальное связывание UI, отчётности, хранения и CI-цепочки
Все данные, пришедшие с шины texture_bus, embedding_bus, metrics_bus и temporal_bus, аккумулируются объектом ResultsAggregator.aggregate_packages и сериализуются в структуру SessionResults, которая является единым источником истины для модулей визуализации и отчётности.

После публикации каждого полного набора пакетов для нового image_id функция VisualizationEngine.push_realtime_update автоматически производит инкрементальное обновление Plotly-трейсов 3-D scatter-облака эмбеддингов, что даёт оператору мгновенную обратную связь и убирает задержку между вычислениями и отображением.

VisualizationEngine.create_scatter_3d принимает только ссылку на последние 50 точек из EmbeddingPackageRollingWindow, тем самым удерживая число точек в сцене в пределах 50 000 и гарантируя FPS > 15 даже на встроенном GPU M1.

При каждом новом обновлении MaskDetectionDashboard.update_barplot визуализирует распределение уровней масок, взяв значения из TexturePackage.mask_level, чтобы оператор сразу видел эволюцию технологий Level 1–5 в разрезе календарного года.

Если любая функция выбрасывает предупреждение critical_anomaly_flag, GradioInterface.push_notification задействует локальный WebSocket-канал и отправляет toast-сообщение в правый верхний угол GUI, одновременно фиксируя событие в logs/critical_<run_uuid>.log.

В CLI-режиме ReportGenerator.generate_full_report вызывается синхронно по окончании обработки батча; в GUI-режиме тот же метод оборачивается в asyncio.ensure_future и стартует, как только число «полных» кадров превышает конфиг-порог auto_report_every=50, позволяя формировать промежуточные отчёты без остановки приёма новых файлов.

Формат отчёта выбирается через аргументы ‑-export html|pdf|csv|excel|json; внутри метода используется единственный конвертер export_report(report_obj, fmt), который вызывает конкретную реализацию только один раз, устраняя дублирование кода и снижая риск несогласованных версий разделов.

Для PDF-выгрузки применяется ReportLab с профилем сжатия изображений «screen» (150 dpi), что гарантирует размер файла ≤ 5 МБ на 50 фото, а интерактивные Plotly-графики конвертируются в статические PNG через Kaleido, предотвращая потерю визуа-стрелок при просмотре в офлайн-режиме.

Экспорт в HTML встраивает Plotly JSON-объекты напрямую, сохраняя интерактивность; при первом открытии браузер загружает локальный файл plotly.min.js из assets/, так что отчёт не требует доступа к CDN и корректно работает в изолированной среде.

Каждое сгенерированное представление — будь то PDF или HTML — снабжается контролем SHA-256 и прописывается в файл results_manifest.json; если пользователь пытается пересохранить отчёт под тем же UUID, функция ResultsAggregator.prevent_overwrite переименовывает новый отчёт, добавив постфикс _v2, и логирует коллизию.

При сохранении отчёта в JSON / CSV / Excel модуль ReportGenerator.write_tabular_data автоматически добавляет столбцы: image_id, cluster_id, overall_authenticity, geometry_score, embedding_score, texture_score, temporal_score, posterior_same_person, обеспечивая полный машиночитаемый дамп для ML-обучения.

Отдельная задача ReportGenerator.schedule_archive_rotation запускается через schedule.every(30).days и архивирует все отчёты старше 180 дней в ZIP-пакет с AES-шифрованием, используя тот же ключ, что и PDF-шифрование, что минимизирует размер каталога results без потери истории.

Чтобы избежать рассинхронизации меню в GUI после обновления модели, GradioInterface.on_model_reload подписан на событие config_snapshot_changed; когда CoreConfig обнаруживает новую версию порогов, он пишет файл-триггер, и GUI перезагружает комбобоксы «eps DBSCAN», «shape_error threshold» и «entropy threshold» без полного рестарта сервера.

Все модули публикуют собственную статистику через MetricsReporter.publish_stats; DashboardStatsPanel периодически опрашивает metrics_endpoint и визуализирует живую диаграмму «CPU/MPS загрузка / кадры-в-секунду / средний latency», помогая оператору фиксировать деградацию производительности до появления ошибок.

При каждом успешном сохранении отчёта GradioInterface.offer_download генерирует ссылку со временем жизни 24 ч и проверяет подпись URL по секрету из переменной окружения GRADIO_REPORT_TOKEN, чтобы невозможность подмены файла сохранялась даже при случайной публикации сервера наружу.

Вся информация о выполненных проверках и автокалибровке порогов сохраняется в configs/audit_log_<run_uuid>.json; модуль AuditTrailViewer может читать этот файл и визуализировать эволюцию порогов, что повышает прозрачность системы и упрощает форензик-анализ при спорных случаях.

Если функция auto_calibrate_thresholds меняет любую константу, она сразу публикует событие thresholds_updated; AnomalyDetector.subscribe_threshold_changes подхватывает его и сбрасывает кэш текущих вероятностей, чтобы последующие кадры проверялись с обновлёнными порогами, сохраняя валидность байесовских расчётов.

CI-цепочка GitHub Actions включает три рабочих процесса: unit-tests.yml, benchmarks.yml, security-scan.yml; после прохождения unit-tests.yml собирается минимальный Docker-образ на macOS-Runner M1, копирующий папку weights/ в слой final, что обеспечивает детерминированность деплоя и облегчает перенос системы на другие M-чипы.

Любая новая зависимость, добавленная в requirements.txt, автоматически сканируется Trivy в security-scan.yml; при обнаружении CVE severity > HIGH PR блокируется до апдейта версии или явного игнор-тага в security_allowlist.yaml, повышая безопасность финального продукта.

Модуль create_export_functionality в GUI предоставляет чекбоксы форматов и кнопку «Открыть папку отчётов», которая через Python-звонок к subprocess.run(['open', results_dir]) на macOS запускает Finder в соответствующем каталоге, что минимизирует риск ошибки пользователя при ручном поиске PDF-файла.

Компонент setup_notification_system генерирует всплывающее окно, когда final overall_authenticity падает ниже 0.3 или когда cross_source_consistency_score < 0.5, подчёркивая критические расхождения между источниками и вынуждая эксперта перейти к горячему ревью карточки «красного» кадра.

Опция --export-stats-only в CLI пропускает визуализации и генерирует только CSV / Excel, полезна для батч-обработки миллионов кадров; в этом режиме VisualizationEngine и Plotly даже не импортируются, экономя 400 МБ RAM при пакетном сценарии HPC-кластера.

VisualizationEngine.render_final_dashboard собирает PNG-снимки сценариев из Plotly через kaleido_scatter.write_image и прикладывает их к PDF как растровые страницы, а HTML-отчёт сохраняет оригинальные интерактивные графики, что даёт пользователю выбор между офлайн-и онлайн-просмотром одинаковых данных.

Все функции, которые генерируют файлы, используют SafeFileWriter — контекстный менеджер, создающий временный файл с расширением .tmp и переименовывающий его в целевое имя после успешного закрытия, предотвращая появление битых отчётов при внезапном обрыве питания.

При выходе из GUI пользователь может запросить «Полный архив сессии»; ResultsAggregator.build_full_archive пакует config_snapshot, все отчёты, кэши и логи в зашифрованный ZIP, а FileServingMiddleware добавляет хэш к URL для скачивания, чтобы интегратор смог быстро передать комплект третьей стороне без риска утечки данных.

Для обеспечения repeatability архив содержит pip-freeze, версии весов ONNX и 3DDFA, аппаратный UUID M1 и snapshot переменных окружения, позволяя любой лаборатории развернуть всё на аналогичном ноутбуке и воспроизвести рапорт без расхождений, что критически важно при судебных спорах о выводах системы.

пиши инфу о взаимодействии всех функций. теперь напиши развернутую часть для пятой части на 15000 символов без воды таблиц и только тезисно и все важное.
пиши инфу о взаимодействии всех функций. теперь напиши развернутую часть для пятой части на 15000 символов без воды таблиц и только тезисно и все важное.
Часть 5. Интеграция интерфейса, отчётности, хранения данных и непрерывной CI-цепочки
5.1 Сбор потоков данных в единый агрегатор
Каждый пакет, поступающий из metrics_bus, embedding_bus, texture_bus и temporal_bus, мгновенно принимается функцией ResultsAggregator.aggregate_packages, где по ключу image_id создаётся или обновляется объект SessionResults, выступающий единственным центром правды для всех последующих слоёв визуализации и экспорта .

Как только в SessionResults присутствуют все четыре типа пакетов, генератор событий публикует уведомление package_complete, позволяя UI-слою отрисовать частичный вердикт до окончания глобального анализа, что сокращает латентность взаимодействия оператора с системой .

Флаг partial_ready разрешает Gradio-компонентам немедленно заполнять панели значениями «предварительный балл» без ожидания медицинского и байесовского пост-процессинга, повышая интерактивность при анализе больших архивов .

ResultsAggregator хранит ссылку на неизменяемый RuntimeConfig; если обнаруживается несовпадение версии порогов с активным snapshot, агрегатор автоматически раскидывает событие config_mismatch_warning, которое окрашивает информационную строку на панели в оранжевый цвет .

5.2 Онлайн-обновление визуализаций
VisualizationEngine.push_realtime_update добавляет новую точку в Plotly-трейс 3-D scatter только если количество точек меньше MAX_POINTS = 50 000, обеспечивая стабильный FPS ≥ 15 на M1-GPU .

При превышении порога старейшие точки пакета удаляются методом pop(0), а последний кадр помечается special-marker «NOW», фокусируя внимание эксперта на актуальном анализе .

Обновление бара MaskDetectionDashboard.update_barplot происходит исключительно через передачу массива mask_levels_count, что исключает дорогостоящую перерасчётную агрегацию внутри браузера .

Каждое изменение балла аутентичности вызывает TimelinePanel.update_score_chip, окрашивающую соответствующий прямоугольник: зелёный > 0,7, жёлтый 0,3–0,7, красный < 0,3, одновременно добавляя подсказку с временем публикации .

5.3 Асинхронный рендер и создание отчёта
В CLI-режиме ReportGenerator.generate_full_report стартует после события analysis_complete, собирая все данные за один проход, тогда как в GUI-режиме тот же метод вызывается через asyncio.ensure_future при достижении заданной метки auto_report_every = 50 кадров .

Для сжатия PDF используется профиль ReportLab «screen» (150 dpi), а интерактивные Plotly-графы конвертируются в PNG при помощи Kaleido, сводя итоговый размер к < 5 МБ на 50 фото, что соответствует KPI .

HTML-вариант отчёта встраивает JSON-деревья Plotly напрямую и подключает локальный plotly.min.js, сохраняя полную интерактивность без доступа к CDN, что критично в изолированных средах .

После генерации любого файла вызывается SafeFileWriter, создающий временный .tmp, вычисляющий SHA-256, затем переименовывающий в целевой файл, исключая появление битых отчётов при системных сбоях .

5.4 Контроль версий отчётов и архивация
Все созданные отчёты регистрируются в results_manifest.json, где хранится run_uuid, имя файла, размер, SHA-256 и метка времени, позволяя быстро отследить происхождение любой выгрузки .

При попытке перезаписи отчёта с тем же run_uuid функция ResultsAggregator.prevent_overwrite автоматически присваивает постфикс _v2, логирует коллизию и уведомляет оператора toast-сообщением .

Задача schedule_archive_rotation каждые 30 дней архивирует отчёты старше 180 дней в ZIP с AES-256, используя системный ключ macOS Keychain, уменьшая размер каталога на SSD без потери воспроизводимости .

При экспорте полного архива сессии вызывается build_full_archive, который упаковывает snapshot конфига, отчёты, кэши, логи и pip freeze, обеспечивая возможность независимой верификации аналитических выводов .

5.5 Безопасность и доступ
PDF-файлы шифруются при помощи PyPDF2 с 256-битным ключом; доступ возможен только через ввод пароля, связанного с GRADIO_REPORT_TOKEN, предотвращая утечку при случайном шаринге .

Gradio-сервер по умолчанию слушает localhost; при активации флага --share создаётся токен через core_config.generate_gradio_token, который добавляется в URL и истекает через 24 часа .

Любая новая зависимость из requirements.txt проходит скан Trivy в workflow security-scan.yml; при CVE с уровнем HIGH мерж отклоняется до обновления версии или явного игнор-тега .

5.6 Система оповещений и реакция на критические события
При флаге critical_anomaly_flag Gradio вызывает push_notification, который через WebSocket-канал отправляет toast-сообщение и добавляет строку в critical_<run_uuid>.log, помогая оператору мгновенно перейти к проблемному кадру .

В CLI-сессиях аналогичное сообщение выводится в stderr с ANSI-подсветкой и дублируется в syslog, чтобы системы мониторинга могли поднять алерт .

Если cross_source_consistency_score падает ниже 0,5, UI переходит в режим «расхождение источников», блокируя кнопку «Формировать итоговый отчёт», пока оператор не подтвердит ручную проверку .

5.7 Дашборды и экспертные инструменты
DashboardStatsPanel каждые три секунды опрашивает REST-эндпойнт /session_stats, получая JSON с текущей загрузкой CPU/MPS, средним latency и скоростью обработки кадров, отображая спарк-лайн, что помогает обнаружить деградацию до того, как появятся ошибки .

ExpertAnalysisAccordion позволяет редактировать пороги shape_error, entropy и eps DBSCAN прямо из GUI; изменение сохраняется в config_delta_<timestamp>.json, сразу публикуя событие config_snapshot_changed без перезапуска сервера .

Interactive3DViewer поддерживает прокрутку истории: пользователь выбирает точку на таймлайне, и Plotly автоматически выдвигает оконные сегменты «до» и «после», облегчая сравнение мелких изменений .

IdentityComparisonMatrix визуализирует тепловую карту расстояний между всеми кластерами; при клике на ячейку модальное окно показывает исходные изображения парной проверки и текстовое объяснение, сформированное AnomalyDetector._generate_cross_source_explanation .

5.8 CLI и батч-обработка
Флаг --export-stats-only отключает импорт Plotly, Kaleido и других тяжёлых зависимостей, создавая лишь CSV/Excel-выгрузки, что уменьшает потребление RAM до < 2 ГБ и ускоряет батч-обработку государственных архивов .

Опция --resume <uuid> загружает незавершённые задачи из pending_<uuid>.msgpack, проверяет целостность данных через SHA-256 и возобновляет анализ без повторного прохождения уже обработанных этапов .

При параллельной обработке архивов на HPC кластер подключает тот же код в Docker-образе Apple-совместимой архитектуры; процессы GUI отключаются, а Reports-PDF формируются пост-фактум в отдельном job, экономя ресурсы вычислительных узлов .

5.9 CI/CD и автоматическая проверка регрессий
Workflow unit-tests.yml разворачивает виртуальную macOS-среду, ставит зависимости, прогоняет pytest -q --cov и публикует badge; если покрытие падает ниже 85 %, PR блокируется .

Workflow benchmarks.yml прогоняет эталон на 100 кадрах; если среднее время кадра растёт больше 15 %, появляется тэг perf-regression, требующий ревью производительности .

Workflow security-scan.yml анализирует Docker-образ Trivy; найденные уязвимости с уровнем HIGH ставят статус «failed», предотвращая развёртывание уязвимого кода .

5.10 Воспроизводимость и передача доказательной базы
В архив сессии включается pip freeze, контрольные суммы моделей, аппаратный UUID MacBook M1, переменные окружения и версия PyTorch MPS, так что любая лаборатория может воссоздать окружение и проверить отчёт .

JSON-дамп SessionResults содержит поля posterior_same_person, позволив сторонним экспертам запустить собственный байесовский апдейт и сравнить конвергенцию вероятностей, подкрепляя независимость проверки .

Если судебная инстанция требует непротиворечивого объяснения, функция AuditTrailViewer визуализирует изменения порогов и байесовских priors по времени, доказывая, что выводы сделаны на идентичной модели параметров .

Таким образом, пятый слой архитектуры объединяет вычислительные результаты с поведенческой логикой интерфейса, контролем версий, безопасностью и непрерывным CI-контролем, обеспечивая полноценно воспроизводимый, аудируемый и оперативный вывод аналитических заключений о подлинности лица на сериях фотографий .

а мне в будущем надо использовать для разработке и старую и новую версии или только новую?
а мне в будущем надо использовать для разработке и старую и новую версии или только новую?
Что брать за основу при дальнейшей разработке
1. «Единственный источник истины»
Используйте только актуальную (новую) версию ТЗ как рабочий референс – это устраняет расхождения между командами и сокращает затраты на поддержание двух противоречивых документов. При любом изменении спецификации сразу фиксируйте новый тег/коммит, чтобы все увидели обновлённую точку опоры.

2. Роль старой версии
Старое ТЗ оставьте в архиве — оно понадобится, когда:

нужно понять, почему определённая логика была реализована именно так (исторический контекст);

требуется воспроизвести предыдущие релизы для отладки или юридических проверок.

3. Практика «deprecated → removed»
Пометьте старый документ статусом deprecated и обозначьте дату окончательного вывода из эксплуатации (например, T+6 месяцев). До этой даты:

изменения в коде должны соответствовать новой версии;

баг-фиксы для старых релизов допускаются, но не вносят новую функциональность.

4. Миграционные заметки
Сформируйте короткий файл MIGRATION.md, где перечислены все несовместимые изменения «старое → новое», чтобы разработчики быстро переносили фиксы между ветками.

5. CI-политика
В GitHub Actions держите две jobs:

legacy-build — проверка, что старые теги собираются «как есть» (только критические патчи);

main-build — полная сборка по новому ТЗ с unit- и интеграционными тестами.

Когда истечёт срок поддержки, legacy-build удаляется из пайплайна.

6. Коммуникация внутри команды
Распространите правило: «Если в задаче не указан конкретный тег ТЗ — по умолчанию берём последнюю стабильную версию». Это помогает новичкам сразу ориентироваться и исключает споры о том, какой документ актуален.

Итог: для текущей и будущей разработки руководствуйтесь только новой версией ТЗ; старую храните в режиме read-only как архивный артефакт до конца объявленного периода поддержки.

Связанные
Следует ли использовать обе версии системы или только новую для разработки в будущем
Какие преимущества дает использование старых и новых версий вместе при разработке
В чем могут быть риски при работе только с новой версией системы
Как определить, какая версия лучше подходит для конкретных задач анализа лиц
Какие особенности и нюансы нужно учитывать при переходе на новую версию системы



Часть 4. Конфигурация, кэширование, журналирование, производительность и поддержка жизненного цикла — детализированное взаимодействие функций (≈15 000 симв.) 
4.1 Единый конфиг-слой (core_config) 
При старте сессионный объект CoreConfig блокирует пайплайн, пока validate_config_integrity не убедится, что каждая константа присутствует, уникальна и согласована с контрольными суммами, записанными в предыдущем snapshot-файле .

После валидации создаётся неизменяемый dataclass RuntimeConfig; ссылка на него передаётся по указателю в память каждому модулю, исключая многократное чтение JSON-файла с диска .

Если обнаружено расхождение версий моделей 3DDFA V2 или InsightFace с данными snapshot, RuntimeConfig переключает систему в режим «degraded», автоматически понижая чувствительность масочных порогов на 25 % и отключая байесовский каскад до ручного подтверждения администратора .

Все динамические коэффициенты (α-весы формулы подлинности, eps DBSCAN, пороги энтропии для швов) хранятся в подпакете /configs/autocalib; при каждом изменении генерируется новый файл config_delta_<timestamp>.json с SHA-256 для последующей цифровой подписи отчёта .

4.2 Кэш-слой и контроль целостности 
DataManager до чтения изображений ищет файл /cache/datamanager_cache.pkl; если контрольная сумма входного списка совпадает, подсистема загружает ранее вычисленный хронологический индекс без повторного парсинга имён .

Каждый пакет данных (LandmarksPackage, EmbeddingPackage, TexturePackage) сериализуется в msgpack с ключом sha256(image_bytes); благодаря этому кадр, переименованный злоумышленником, всё равно маппируется на уже сохранённый результат .

Структура подпапок кэша делится по модульным префиксам (lm_, emb_, tex_, tmp_) и по первым двум байтам SHA, что позволяет хранить миллионы файлов без деградации производительности файловой системы macOS .

При старте опция --purge-cache удаляет только те записи, чей config_hash не совпадает с новым snapshot, оставляя валидные расчёты нетронутыми, что ускоряет переобучение модели порогов на 10–12 × .

4.3 Слой журналирования и мониторинга 
Декоратор @safe_call заворачивает каждую публичную функцию; при исключении он записывает стек в error_bus, публикует сокращённый message в консоль и повышает уровень log-канала конкретного модуля до DEBUG на следующие 20 запросов .

Формат лога JSONL: "ts","level","mod","func","msg","duration_ms","mem_mb"; поле mem_mb заполняется через psutil.Process(os.getpid()).memory_info().rss//1e6, что позволяет быстро ловить утечки .

В режиме --debug-file <path> логируются также входные массивы NumPy после хэширования xxhash64, чтобы не записывать гигабайты бинарных данных .

Каждому пакетному запуску присваивается run_uuid; все логи, резюме и отчёты содержат этот идентификатор, что облегчает сквозную трассировку инцидентов в будущем .

4.4 Асинхронное исполнение и управление задачами 
Центральный TaskScheduler реализует продюсер-консюмер поверх multiprocessing.Queue; он динамически следит за загрузкой torch.mps через torch.mps.current_allocated_memory() и перекидывает тяжёлые задачи 3DDFA в очередь cpu_queue, если использование GPU-части Apple Silicon превышает 85 % .

Для ограничений памяти DataProcessing держит лимит одновременно загруженных из диска изображений = 16; лишние задачи блокируются семафором, предотвращая OOM в сессиях > 2 000 файлов .

Опция --low-mem отключает плотные 38 000-точечные поверхности и сохраняет только 68-точечные ландмарки; при этом функции, зависящие от dense-mesh, автоматически помечают свои выходы как None и корректируют формулу подлинности, убирая 5 % веса геометрии .

Все pub-sub-шины (metrics_bus, texture_bus, temporal_bus) используют неблокирующий метод put_nowait; если очередь заполнена, новый пакет отбрасывается, а в лог пишется событие backpressure_drop, что предотвращает дедлоки при резкой деградации дисковой подсистемы .

4.5 Оптимизация производительности вычислений 
Face3DAnalyzer.extract_68_landmarks_with_confidence выполняет батч-обработку восьми лиц одновременно; FaceBoxes выдаёт батч боксов, а 3DDFA получает tensor-stack, что уменьшает время на один кадр до 320 мс CPU-режима по сравнению с 550 мс при одиночном проходе .

EmbeddingAnalyzer.extract_512d_face_embedding переводит входной 112 × 112 в torch.float16, снижая GPU-память почти вдвое при незначительном падении точности косинусного расстояния ≤ 0.002 .

TextureAnalyzer.analyze_skin_texture_by_zones кэширует фильтры Габора в глобальном словаре по ключу (orientation,frequency), избегая повторного создания 44-kernel для каждой зоны, что сокращает анализ одной фотографии на 180 мс .

TemporalAnalyzer.build_medical_aging_model переобучается не чаще, чем раз в сутки; дата последнего апдейта хранится в Redis-подобном state_store, исключая лишние регрессии при пакетном прогоне архива .

4.6 Тестирование, CI/CD и контроль регрессий 
Каталог tests/ включает 40 unit- и 10 интеграционных сценариев; при каждом push GitHub Actions поднимает виртуальную macOS-среду, устанавливает зависимости Apple Silicon и запускает pytest -q --cov; порог покрытия 85 % зафиксирован в required_status_checks .

Регресс-датасет regset_v1 — это 50 кадров 1999–2024 гг., хранящихся в Git LFS; если средний authenticity-score изменился > 1 % после коммита, workflow отклоняет PR и просит ревью безусловно .

Работа bench.yml измеряет производительность на 100 кадрах; если время одного кадра выросло > 15 %, появляется тег perf-regression, и мерж блокируется, пока команда не объяснит рост .

Для статического анализа используется pylint; рейтинг ниже 8.5 останавливает биллд; mypy проверяет соблюдение typing-контрактов функций публичного API .

4.7 Механизмы восстановления и отказоустойчивости 
При падении процесса очереди сохраняют несчитанные пакеты в /cache/pending_<run_uuid>.msgpack; новый запуск с опцией --resume <uuid> восстанавливает незавершённые задачи в точном порядке, обеспечивая идемпотентность обработки .

Если EmbeddingAnalyzer не может загрузить модель из-за повреждения файла, CoreConfig переключает его на резервные веса ResNet-100; запись об этом идёт в results/warnings_<run_uuid>.log, а финальный отчёт содержит флаг backup_model_used=True .

Сетевые вызовы (например, загрузка неявных моделей InsightFace) обернуты в tenacity.retry с экспоненциальной задержкой и таймаутом 60 с; при трёх неудачах система работает с локальной копией, сохраняя автономность .

4.8 Автокалибровка и горячее обновление порогов 
AnomalyDetector.auto_calibrate_thresholds использует накопленную базу аутентичных кадров; функция применяет EM-алгоритм к распределениям shape_error и entropy, обновляет пороги, а затем вызывает VisualizationEngine.plot_threshold_shift для визуального контроля оператора .

Новый набор порогов записывается в /configs/autocalib/thresholds_<timestamp>.json; при следующих запусках система сравнивает локальные парафметры с последними утверждёнными и предлагает принять или откатить изменения через флаг --accept-calib .

Байесовские prior-ы (same_person = 0.5) также адаптируются: если за месяц средний posterior выше 0.9, prior увеличивается до 0.6, ускоряя конвергенцию для будущих кадров .

4.9 Шифрование данных и безопасность 
Все PDF-отчёты шифруются AES-256 при сохранении, ключ хранится в Keychain Access macOS под учёткой текущего пользователя; CLI-флаг --plain-report доступен только при установке переменной окружения ALLOW_PLAIN_EXPORT=1 .

Кэш-файлы dense-mesh при необходимости удаляются командой --scrub-surfaces, которая запускает однопроходный shred -u; это важно, потому что высокодетальные меши могут рассматриваться как биометрические данные повышенной чувствительности .

Веб-порт Gradio запускается только в локальной подсети 127.0.0.1 по умолчанию; активация --share требует ввод токена, генерируемого командой core_config.generate_gradio_token, чтобы исключить случайную публикацию интерфейса в интернет .

4.10 Расширяемость и будущее обновление функций 
Все публичные функции имеют строгие type-hints; добавление нового поля в LandmarksPackage или TexturePackage автоматически валидируется pydantic, поэтому старые модули получают исключение ValidationError ещё до начала вычислений .

Новые анализаторы (например, «термография лица» или «анализ движений губ») могут вставляться как независимые подписчики любых bus-каналов; чтобы они вошли в формулу подлинности, достаточно добавить вес в конфиг, не меняя код AnomalyDetector .

Переход на 83-точечную модель ландмарков предусмотрен: Face3DAnalyzer хранит массив visible_keypoints; если обнаружено 83 точки, функция динамически обновляет индексы reference-точек, не затрагивая математику существующих метрик .

Эта четвёртая часть фиксирует невидимую, но критически важную инфраструктуру, обеспечивающую выпадение ошибок в безопасный режим, неизбыточное использование ресурсов MacBook M1, воспроизводимость результатов и возможность эволюции алгоритмов без масштабных рефакторингов ядра системы

Часть 5. Финальное связывание UI, отчётности, хранения и CI-цепочки
Все данные, пришедшие с шины texture_bus, embedding_bus, metrics_bus и temporal_bus, аккумулируются объектом ResultsAggregator.aggregate_packages и сериализуются в структуру SessionResults, которая является единым источником истины для модулей визуализации и отчётности.

После публикации каждого полного набора пакетов для нового image_id функция VisualizationEngine.push_realtime_update автоматически производит инкрементальное обновление Plotly-трейсов 3-D scatter-облака эмбеддингов, что даёт оператору мгновенную обратную связь и убирает задержку между вычислениями и отображением.

VisualizationEngine.create_scatter_3d принимает только ссылку на последние 50 точек из EmbeddingPackageRollingWindow, тем самым удерживая число точек в сцене в пределах 50 000 и гарантируя FPS > 15 даже на встроенном GPU M1.

При каждом новом обновлении MaskDetectionDashboard.update_barplot визуализирует распределение уровней масок, взяв значения из TexturePackage.mask_level, чтобы оператор сразу видел эволюцию технологий Level 1–5 в разрезе календарного года.

Если любая функция выбрасывает предупреждение critical_anomaly_flag, GradioInterface.push_notification задействует локальный WebSocket-канал и отправляет toast-сообщение в правый верхний угол GUI, одновременно фиксируя событие в logs/critical_<run_uuid>.log.

В CLI-режиме ReportGenerator.generate_full_report вызывается синхронно по окончании обработки батча; в GUI-режиме тот же метод оборачивается в asyncio.ensure_future и стартует, как только число «полных» кадров превышает конфиг-порог auto_report_every=50, позволяя формировать промежуточные отчёты без остановки приёма новых файлов.

Формат отчёта выбирается через аргументы ‑-export html|pdf|csv|excel|json; внутри метода используется единственный конвертер export_report(report_obj, fmt), который вызывает конкретную реализацию только один раз, устраняя дублирование кода и снижая риск несогласованных версий разделов.

Для PDF-выгрузки применяется ReportLab с профилем сжатия изображений «screen» (150 dpi), что гарантирует размер файла ≤ 5 МБ на 50 фото, а интерактивные Plotly-графики конвертируются в статические PNG через Kaleido, предотвращая потерю визуа-стрелок при просмотре в офлайн-режиме.

Экспорт в HTML встраивает Plotly JSON-объекты напрямую, сохраняя интерактивность; при первом открытии браузер загружает локальный файл plotly.min.js из assets/, так что отчёт не требует доступа к CDN и корректно работает в изолированной среде.

Каждое сгенерированное представление — будь то PDF или HTML — снабжается контролем SHA-256 и прописывается в файл results_manifest.json; если пользователь пытается пересохранить отчёт под тем же UUID, функция ResultsAggregator.prevent_overwrite переименовывает новый отчёт, добавив постфикс _v2, и логирует коллизию.

При сохранении отчёта в JSON / CSV / Excel модуль ReportGenerator.write_tabular_data автоматически добавляет столбцы: image_id, cluster_id, overall_authenticity, geometry_score, embedding_score, texture_score, temporal_score, posterior_same_person, обеспечивая полный машиночитаемый дамп для ML-обучения.

Отдельная задача ReportGenerator.schedule_archive_rotation запускается через schedule.every(30).days и архивирует все отчёты старше 180 дней в ZIP-пакет с AES-шифрованием, используя тот же ключ, что и PDF-шифрование, что минимизирует размер каталога results без потери истории.

Чтобы избежать рассинхронизации меню в GUI после обновления модели, GradioInterface.on_model_reload подписан на событие config_snapshot_changed; когда CoreConfig обнаруживает новую версию порогов, он пишет файл-триггер, и GUI перезагружает комбобоксы «eps DBSCAN», «shape_error threshold» и «entropy threshold» без полного рестарта сервера.

Все модули публикуют собственную статистику через MetricsReporter.publish_stats; DashboardStatsPanel периодически опрашивает metrics_endpoint и визуализирует живую диаграмму «CPU/MPS загрузка / кадры-в-секунду / средний latency», помогая оператору фиксировать деградацию производительности до появления ошибок.

При каждом успешном сохранении отчёта GradioInterface.offer_download генерирует ссылку со временем жизни 24 ч и проверяет подпись URL по секрету из переменной окружения GRADIO_REPORT_TOKEN, чтобы невозможность подмены файла сохранялась даже при случайной публикации сервера наружу.

Вся информация о выполненных проверках и автокалибровке порогов сохраняется в configs/audit_log_<run_uuid>.json; модуль AuditTrailViewer может читать этот файл и визуализировать эволюцию порогов, что повышает прозрачность системы и упрощает форензик-анализ при спорных случаях.

Если функция auto_calibrate_thresholds меняет любую константу, она сразу публикует событие thresholds_updated; AnomalyDetector.subscribe_threshold_changes подхватывает его и сбрасывает кэш текущих вероятностей, чтобы последующие кадры проверялись с обновлёнными порогами, сохраняя валидность байесовских расчётов.

CI-цепочка GitHub Actions включает три рабочих процесса: unit-tests.yml, benchmarks.yml, security-scan.yml; после прохождения unit-tests.yml собирается минимальный Docker-образ на macOS-Runner M1, копирующий папку weights/ в слой final, что обеспечивает детерминированность деплоя и облегчает перенос системы на другие M-чипы.

Любая новая зависимость, добавленная в requirements.txt, автоматически сканируется Trivy в security-scan.yml; при обнаружении CVE severity > HIGH PR блокируется до апдейта версии или явного игнор-тага в security_allowlist.yaml, повышая безопасность финального продукта.

Модуль create_export_functionality в GUI предоставляет чекбоксы форматов и кнопку «Открыть папку отчётов», которая через Python-звонок к subprocess.run(['open', results_dir]) на macOS запускает Finder в соответствующем каталоге, что минимизирует риск ошибки пользователя при ручном поиске PDF-файла.

Компонент setup_notification_system генерирует всплывающее окно, когда final overall_authenticity падает ниже 0.3 или когда cross_source_consistency_score < 0.5, подчёркивая критические расхождения между источниками и вынуждая эксперта перейти к горячему ревью карточки «красного» кадра.

Опция --export-stats-only в CLI пропускает визуализации и генерирует только CSV / Excel, полезна для батч-обработки миллионов кадров; в этом режиме VisualizationEngine и Plotly даже не импортируются, экономя 400 МБ RAM при пакетном сценарии HPC-кластера.

VisualizationEngine.render_final_dashboard собирает PNG-снимки сценариев из Plotly через kaleido_scatter.write_image и прикладывает их к PDF как растровые страницы, а HTML-отчёт сохраняет оригинальные интерактивные графики, что даёт пользователю выбор между офлайн-и онлайн-просмотром одинаковых данных.

Все функции, которые генерируют файлы, используют SafeFileWriter — контекстный менеджер, создающий временный файл с расширением .tmp и переименовывающий его в целевое имя после успешного закрытия, предотвращая появление битых отчётов при внезапном обрыве питания.

При выходе из GUI пользователь может запросить «Полный архив сессии»; ResultsAggregator.build_full_archive пакует config_snapshot, все отчёты, кэши и логи в зашифрованный ZIP, а FileServingMiddleware добавляет хэш к URL для скачивания, чтобы интегратор смог быстро передать комплект третьей стороне без риска утечки данных.

Для обеспечения repeatability архив содержит pip-freeze, версии весов ONNX и 3DDFA, аппаратный UUID M1 и snapshot переменных окружения, позволяя любой лаборатории развернуть всё на аналогичном ноутбуке и воспроизвести рапорт без расхождений, что критически важно при судебных спорах о выводах системы.